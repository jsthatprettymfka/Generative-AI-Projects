{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36ffa21cec33455c9325855101050c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdfb4180ea0c404abee09570a5b71305",
              "IPY_MODEL_88ccf20395774d0b97db2eebf959ac0f",
              "IPY_MODEL_c183aece54a5456ab2470b0f8345b20f"
            ],
            "layout": "IPY_MODEL_97a13bf736d74640b82336e93019f27a"
          }
        },
        "fdfb4180ea0c404abee09570a5b71305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f51a77be3f3a4764a7e64b36c120c0a2",
            "placeholder": "​",
            "style": "IPY_MODEL_854af046ea9c4181afe4ab94639ef570",
            "value": "Parsing nodes: 100%"
          }
        },
        "88ccf20395774d0b97db2eebf959ac0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70169928ce734c7b87d4c1ced975b899",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_293a0de5d19f432c8d5ff316a3e583c2",
            "value": 6
          }
        },
        "c183aece54a5456ab2470b0f8345b20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d1140e299b491ead8801260689159c",
            "placeholder": "​",
            "style": "IPY_MODEL_bbf618aaf0a847f69f4b69471d7b72ee",
            "value": " 6/6 [00:00&lt;00:00, 121.34it/s]"
          }
        },
        "97a13bf736d74640b82336e93019f27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51a77be3f3a4764a7e64b36c120c0a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854af046ea9c4181afe4ab94639ef570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70169928ce734c7b87d4c1ced975b899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "293a0de5d19f432c8d5ff316a3e583c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2d1140e299b491ead8801260689159c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf618aaf0a847f69f4b69471d7b72ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f980be4fc91a435b8f4ea2a2c4c42815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78b9620d4fbb4887bb8f7c9f23c2818e",
              "IPY_MODEL_ab9ea5cfc90743d5ab9273efe87e00d0",
              "IPY_MODEL_3e170f1b0ab54edabc29b1153335d41a"
            ],
            "layout": "IPY_MODEL_df2169c7e96642a9b0399e88df0ffb46"
          }
        },
        "78b9620d4fbb4887bb8f7c9f23c2818e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_139c1b4cfa6e4260b62eeaff1152beec",
            "placeholder": "​",
            "style": "IPY_MODEL_9bf0b21feab94823b98f0a00829260d4",
            "value": "modules.json: 100%"
          }
        },
        "ab9ea5cfc90743d5ab9273efe87e00d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b3d7d7850c642539d7933f4eb73cb89",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d7c38a3fda84fb08e06adbfcac2081f",
            "value": 349
          }
        },
        "3e170f1b0ab54edabc29b1153335d41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be3c35db15ae4a0ea5b0bf005f92f25e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee0ff8f1c6b9491fb5510240c573fc26",
            "value": " 349/349 [00:00&lt;00:00, 9.39kB/s]"
          }
        },
        "df2169c7e96642a9b0399e88df0ffb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "139c1b4cfa6e4260b62eeaff1152beec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf0b21feab94823b98f0a00829260d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b3d7d7850c642539d7933f4eb73cb89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7c38a3fda84fb08e06adbfcac2081f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be3c35db15ae4a0ea5b0bf005f92f25e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0ff8f1c6b9491fb5510240c573fc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51c526a15879492a8863e24c63c10051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1950900b4a90426ca9718f661ee3f0e8",
              "IPY_MODEL_04efda97090d4ecd89dd2f6689d54b0f",
              "IPY_MODEL_89fa4c155a4f40b184f11929e352e260"
            ],
            "layout": "IPY_MODEL_c93c061945e547a0918d15d6d792c729"
          }
        },
        "1950900b4a90426ca9718f661ee3f0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cf379caa1b848e98dbd8ad55eca9331",
            "placeholder": "​",
            "style": "IPY_MODEL_33502cea8efa40019b5baf3a66646ba0",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "04efda97090d4ecd89dd2f6689d54b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b84d92a5cab24d9092f2ef2b19e24f13",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4894d7e5e82b47ecba12507c5387b8a3",
            "value": 124
          }
        },
        "89fa4c155a4f40b184f11929e352e260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c5bca121ad94e2cab48b86b01b3a501",
            "placeholder": "​",
            "style": "IPY_MODEL_acd160290ba845a0ba921ec05222c695",
            "value": " 124/124 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "c93c061945e547a0918d15d6d792c729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cf379caa1b848e98dbd8ad55eca9331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33502cea8efa40019b5baf3a66646ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b84d92a5cab24d9092f2ef2b19e24f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4894d7e5e82b47ecba12507c5387b8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c5bca121ad94e2cab48b86b01b3a501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd160290ba845a0ba921ec05222c695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d245c61e6a8f42f3827bc14fb15ebc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff84cf7b378548f49a8195ab0d7cc64a",
              "IPY_MODEL_03fa4f8e54bb4402818954f8524ddb53",
              "IPY_MODEL_054d3374c6414c74bb2a48e7ef7d6ca1"
            ],
            "layout": "IPY_MODEL_f4f0eb65357f44c8a70ed405b68e26a9"
          }
        },
        "ff84cf7b378548f49a8195ab0d7cc64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59a89944b5ce47ae8638e9f3a0677b77",
            "placeholder": "​",
            "style": "IPY_MODEL_cf13a5b9186348459b58673e55f7ad77",
            "value": "README.md: 100%"
          }
        },
        "03fa4f8e54bb4402818954f8524ddb53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f6e99f58a274c82b859702196bb35c5",
            "max": 94783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b60052b8d1b4764bf6511b79c965106",
            "value": 94783
          }
        },
        "054d3374c6414c74bb2a48e7ef7d6ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84af73e650b4474cba16d0437e17cd5a",
            "placeholder": "​",
            "style": "IPY_MODEL_a81229475c7c492f971fc085ce85f4a9",
            "value": " 94.8k/94.8k [00:00&lt;00:00, 2.60MB/s]"
          }
        },
        "f4f0eb65357f44c8a70ed405b68e26a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a89944b5ce47ae8638e9f3a0677b77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf13a5b9186348459b58673e55f7ad77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f6e99f58a274c82b859702196bb35c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b60052b8d1b4764bf6511b79c965106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84af73e650b4474cba16d0437e17cd5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a81229475c7c492f971fc085ce85f4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64e55b7ace8a452b8c5f9c9dc4f7be65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15a1bdded877486288bfc093be686635",
              "IPY_MODEL_234c3bdf518a4407909f01126ab50c7e",
              "IPY_MODEL_6cbaeed821e244ac91c0f99cead49529"
            ],
            "layout": "IPY_MODEL_4a5605d4a9ef42798134af2929bb1180"
          }
        },
        "15a1bdded877486288bfc093be686635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2849e01db2432e91c02742a7fb2164",
            "placeholder": "​",
            "style": "IPY_MODEL_75476b2c67c347089fa9315e29574248",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "234c3bdf518a4407909f01126ab50c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e6be3da67641d2a80c0430495eb9f7",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db31663d454d46cb804cb938ccdfc0be",
            "value": 52
          }
        },
        "6cbaeed821e244ac91c0f99cead49529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593f73849a0f409fa21a62a003b1e6fd",
            "placeholder": "​",
            "style": "IPY_MODEL_28bbdb8c53864d6397035de3444d0986",
            "value": " 52.0/52.0 [00:00&lt;00:00, 3.76kB/s]"
          }
        },
        "4a5605d4a9ef42798134af2929bb1180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2849e01db2432e91c02742a7fb2164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75476b2c67c347089fa9315e29574248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e6be3da67641d2a80c0430495eb9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db31663d454d46cb804cb938ccdfc0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "593f73849a0f409fa21a62a003b1e6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bbdb8c53864d6397035de3444d0986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1e591b4efb341a896e535b243d648ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b1c898bc9174c068cee95488275e23a",
              "IPY_MODEL_0a3c476bf2bb4beb9f71ff9a2c1101d7",
              "IPY_MODEL_4a7ef0cdebc84f6bb69420e2b0314d14"
            ],
            "layout": "IPY_MODEL_65c0c9e0eef34cb0afea1c25abdc3334"
          }
        },
        "1b1c898bc9174c068cee95488275e23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ded352db2b4adf970f05719a934049",
            "placeholder": "​",
            "style": "IPY_MODEL_b5f6cb59d44f45ba9e9b9811ebf389a2",
            "value": "config.json: 100%"
          }
        },
        "0a3c476bf2bb4beb9f71ff9a2c1101d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d1e0812554f4a48bdd9adf500cf69f6",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_097af4545c5f47c9b017e23fbccb523f",
            "value": 743
          }
        },
        "4a7ef0cdebc84f6bb69420e2b0314d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3a1d189459488c998abf597c3e3d40",
            "placeholder": "​",
            "style": "IPY_MODEL_39177a46d18f4cbfb6c7b36961134aee",
            "value": " 743/743 [00:00&lt;00:00, 38.2kB/s]"
          }
        },
        "65c0c9e0eef34cb0afea1c25abdc3334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ded352db2b4adf970f05719a934049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f6cb59d44f45ba9e9b9811ebf389a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d1e0812554f4a48bdd9adf500cf69f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097af4545c5f47c9b017e23fbccb523f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b3a1d189459488c998abf597c3e3d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39177a46d18f4cbfb6c7b36961134aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "078af90ff87549f5bb1f91c5ef0d4799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4d1fe95777642f6a7b929a7bc497fa6",
              "IPY_MODEL_41616dad3799421086763199d6e28eab",
              "IPY_MODEL_8d36c5d953a74a6494f34642eb3519bd"
            ],
            "layout": "IPY_MODEL_d971290f87f84ce8999a7ae22ef0c93e"
          }
        },
        "b4d1fe95777642f6a7b929a7bc497fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f16a5497720a415a82041e3a1088524e",
            "placeholder": "​",
            "style": "IPY_MODEL_747665af4d8b4d6c8d98ce1b55f4c4a2",
            "value": "model.safetensors: 100%"
          }
        },
        "41616dad3799421086763199d6e28eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eaadd4d6a8e4b979d83264435a1e0a1",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ce3ad8d20eb4090a03ae30fc7dc09bd",
            "value": 133466304
          }
        },
        "8d36c5d953a74a6494f34642eb3519bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49deb0d353614295bd9d7a91948c7c59",
            "placeholder": "​",
            "style": "IPY_MODEL_cdc700d793b047a7a9c58de730119d54",
            "value": " 133M/133M [00:01&lt;00:00, 124MB/s]"
          }
        },
        "d971290f87f84ce8999a7ae22ef0c93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f16a5497720a415a82041e3a1088524e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747665af4d8b4d6c8d98ce1b55f4c4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eaadd4d6a8e4b979d83264435a1e0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ce3ad8d20eb4090a03ae30fc7dc09bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49deb0d353614295bd9d7a91948c7c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc700d793b047a7a9c58de730119d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efe0a857fda44d448a0aeba0894fda31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_257ce9bd01a140e585a06a0f86bb34ba",
              "IPY_MODEL_2c1b777ded924b03bf14f0a87320a5ca",
              "IPY_MODEL_205dec4acf7f4bebb411a9ca6fd4ad3d"
            ],
            "layout": "IPY_MODEL_bd9eca4c3472415098486041095a3513"
          }
        },
        "257ce9bd01a140e585a06a0f86bb34ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08e0484aeff84bbba964e543ed20487f",
            "placeholder": "​",
            "style": "IPY_MODEL_0eebe6c8b9ec4fd29c897dfebbb4d0fa",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2c1b777ded924b03bf14f0a87320a5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ecc29e2609c4aa9b9140cbfd44c5968",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27386af8ac89442195a9af3e3034ef71",
            "value": 366
          }
        },
        "205dec4acf7f4bebb411a9ca6fd4ad3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6957cbe905fd4f84b7263c3287609f28",
            "placeholder": "​",
            "style": "IPY_MODEL_d5449aba229f4089998809a8580dc0fa",
            "value": " 366/366 [00:00&lt;00:00, 9.76kB/s]"
          }
        },
        "bd9eca4c3472415098486041095a3513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e0484aeff84bbba964e543ed20487f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eebe6c8b9ec4fd29c897dfebbb4d0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ecc29e2609c4aa9b9140cbfd44c5968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27386af8ac89442195a9af3e3034ef71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6957cbe905fd4f84b7263c3287609f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5449aba229f4089998809a8580dc0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4316c34b4b654a6989370622c151535b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fc9f54f575049b8bf2d88cc522f4db4",
              "IPY_MODEL_cfc4fc21d5be4f26adc8f1b513a00391",
              "IPY_MODEL_2baeb592c82f47b584d6efdc407ef4e4"
            ],
            "layout": "IPY_MODEL_fd1f69c5c9c541178874ed416799b9ad"
          }
        },
        "3fc9f54f575049b8bf2d88cc522f4db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35b2c2ed3042486fb08ccb850a9665a8",
            "placeholder": "​",
            "style": "IPY_MODEL_08788d73f9e044b691b08e41ed06ff82",
            "value": "vocab.txt: 100%"
          }
        },
        "cfc4fc21d5be4f26adc8f1b513a00391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ff45cd8c354cde89e41cdc3dee81a5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee77ee6750434249abc9b7ebb8f211f8",
            "value": 231508
          }
        },
        "2baeb592c82f47b584d6efdc407ef4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f25f20e7e0fd4e1fb7688b150a4ddac5",
            "placeholder": "​",
            "style": "IPY_MODEL_31594aae0a5a4813b1bf0afa80d70efe",
            "value": " 232k/232k [00:00&lt;00:00, 4.77MB/s]"
          }
        },
        "fd1f69c5c9c541178874ed416799b9ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b2c2ed3042486fb08ccb850a9665a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08788d73f9e044b691b08e41ed06ff82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9ff45cd8c354cde89e41cdc3dee81a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee77ee6750434249abc9b7ebb8f211f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f25f20e7e0fd4e1fb7688b150a4ddac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31594aae0a5a4813b1bf0afa80d70efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "745ed88420024dafb272c561e2ce7e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b992ab0fbd0043f4be80f352ee8c41b9",
              "IPY_MODEL_b44bf6b2d35a4b1b9fdbc75c552fa618",
              "IPY_MODEL_a6d29c52abf5477188a244cfebcb8cec"
            ],
            "layout": "IPY_MODEL_7bb4ddd93c9e405b957d2d366dbc243c"
          }
        },
        "b992ab0fbd0043f4be80f352ee8c41b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d8f7cc375c4f4282940e897b445090",
            "placeholder": "​",
            "style": "IPY_MODEL_4463aa81785c46cab72275580862cd47",
            "value": "tokenizer.json: 100%"
          }
        },
        "b44bf6b2d35a4b1b9fdbc75c552fa618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c1f24ba3cd4549bd7bee39983d45d5",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ce6c97b26c48e29cb05b2010ea3770",
            "value": 711396
          }
        },
        "a6d29c52abf5477188a244cfebcb8cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cabe565247f84642b11d7e5d8beef466",
            "placeholder": "​",
            "style": "IPY_MODEL_ddb2b3acb7bd4fc689ab1b871ec254fa",
            "value": " 711k/711k [00:00&lt;00:00, 18.3MB/s]"
          }
        },
        "7bb4ddd93c9e405b957d2d366dbc243c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d8f7cc375c4f4282940e897b445090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4463aa81785c46cab72275580862cd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57c1f24ba3cd4549bd7bee39983d45d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ce6c97b26c48e29cb05b2010ea3770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cabe565247f84642b11d7e5d8beef466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb2b3acb7bd4fc689ab1b871ec254fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "753b846ac64940d8bd84a5fd3ee2e11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b09d53aee6f4c90bb43b9702bdba947",
              "IPY_MODEL_3db58e2b7af149c796b7f15e351335d2",
              "IPY_MODEL_e45a8aa7da434ed08e420e59000046de"
            ],
            "layout": "IPY_MODEL_a8d066adfb4d4cf989aa072e804c5618"
          }
        },
        "7b09d53aee6f4c90bb43b9702bdba947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aaa1679bc614bb090069a7b2e6cfdfe",
            "placeholder": "​",
            "style": "IPY_MODEL_2b51bab97f804ec79b009a1c8aeb94cc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3db58e2b7af149c796b7f15e351335d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b45e9bc31a426ebdc4ddad63ac519d",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b632c62364634643bd81eded98913091",
            "value": 125
          }
        },
        "e45a8aa7da434ed08e420e59000046de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_543058cc902a4c7ea4bc08c7f98419f9",
            "placeholder": "​",
            "style": "IPY_MODEL_be1330a02c134c77b8d345448c6a9b7b",
            "value": " 125/125 [00:00&lt;00:00, 7.42kB/s]"
          }
        },
        "a8d066adfb4d4cf989aa072e804c5618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aaa1679bc614bb090069a7b2e6cfdfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b51bab97f804ec79b009a1c8aeb94cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b45e9bc31a426ebdc4ddad63ac519d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b632c62364634643bd81eded98913091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "543058cc902a4c7ea4bc08c7f98419f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be1330a02c134c77b8d345448c6a9b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40d8f8cfb60f4dbe8381cb54de8b6e18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e7d3944fe76457588fa01649c04c4a1",
              "IPY_MODEL_b359c2c41b504b0db995d069b38258ef",
              "IPY_MODEL_f33e695f9872489c9b6c1374789d800f"
            ],
            "layout": "IPY_MODEL_e21a62ec94814a24aa040b47e4f5b9f0"
          }
        },
        "2e7d3944fe76457588fa01649c04c4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c57b4f598784461eba930e764cc404cb",
            "placeholder": "​",
            "style": "IPY_MODEL_f6774bc3907e451fa3a77330bad5fbdd",
            "value": "config.json: 100%"
          }
        },
        "b359c2c41b504b0db995d069b38258ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1849cdfb296942c9a9fb596a5e32d5d5",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7364a0090c5447e9d22b2d4c9a7aa4a",
            "value": 190
          }
        },
        "f33e695f9872489c9b6c1374789d800f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01de4f211cd546f3b364d1320674a209",
            "placeholder": "​",
            "style": "IPY_MODEL_fae5c9f523df4ce887d477dcb3d83740",
            "value": " 190/190 [00:00&lt;00:00, 7.09kB/s]"
          }
        },
        "e21a62ec94814a24aa040b47e4f5b9f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57b4f598784461eba930e764cc404cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6774bc3907e451fa3a77330bad5fbdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1849cdfb296942c9a9fb596a5e32d5d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7364a0090c5447e9d22b2d4c9a7aa4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01de4f211cd546f3b364d1320674a209": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fae5c9f523df4ce887d477dcb3d83740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twjIi6bl1Yoz",
        "outputId": "f5b2df9a-2f7d-4556-b189-81fe7115120b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "HBJQIID31m6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#installing llama\n",
        "%pip install -Uq llama-index\n",
        "%pip install -Uq llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhEdUyNa1rvR",
        "outputId": "ae1bfa10-6a0c-46e4-a37c-512a6b6dd322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.3/267.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXTRACT THE COMPONENTS FOR OUR DOC"
      ],
      "metadata": {
        "id": "rhiLop6n2GX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# directory reader which extracts the text from every single doc\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "documents = SimpleDirectoryReader(input_dir = './data').load_data()\n",
        "\n",
        "# file name as id\n",
        "# doc_name_as_id = SimpleDirectoryReader(input_dir = './data', filename_as_id = True).load_data()"
      ],
      "metadata": {
        "id": "YQuhDA1V2uyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rounding up\n",
        "# we r gnerating a doc for each page in the pdf\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkgRrE9K5qpe",
        "outputId": "ed938e71-c4ed-4d38-8ed9-944f2b1617c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa6Exkb150bl",
        "outputId": "f0fa88d5-f0f9-4412-c7b2-3d196945cb14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(id_='9a7eee2b-f46f-440a-a9ac-5f3e546fc72f', embedding=None, metadata={'page_label': '1', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Face Liveness Detection Using a sequential CNN\\ntechnique\\nAbdelrahamn Ashraf Mohamed, Marwan Mohamed Nagah, Mohamed Gamal Abdelmonem,\\nMohamed Yasser Ahmed, Mahmoud El-Sahhar, Fatma Helmy Ismail\\nFaculty of Computer Science\\nMisr International University, Cario, Egypt\\nabdelrahman1711335, marwan1709805, mohamed1709263,\\nmohamed1709620, mahmoud.ezzat, fatma.helmy {@miuegypt.edu.eg}\\nAbstract—One of the most widely used biometric approaches\\nis face recognition. Face recognition is used in many Fields.\\nOne of these ﬁelds is mobile devices authentication. While the\\nnumber of mobile device users increasing year after year, the\\nneed for mobile security is also gaining ground. However, face\\nrecognition can be easily attacked by a malicious face spooﬁng.\\nThat is intended to deceive the face recognition system by facial\\npictures obtained from images or videos. Other cheaters show\\nthe mask of an authorized person to fool the recognition camera\\ninto a real person. Liveness detection is an important research\\ntopic to detect face spooﬁng. The proposed approach in this\\npaper is a deep learning technique which is a sequential CNN\\n(convolution Neural Network) divided into a feature extraction\\nstage and a classiﬁcation stage. The dataset used is CelebA-\\nSpoof (2020) collected to recognize live and non-live faces. The\\nexperiment is performed on a part of the CelebA-Spoof dataset.\\nThe performance of the proposed approach is measured in terms\\nof accuracy. The accuracy of testing the system on unseen data\\nis 87% and the area under ROC curve is 0.535. there are many\\nnew techniques are intended to be used in future work such as\\ncapsule neural networks is expected to improves our results.\\nIndex T erms—deep learning, convolution neural network, face\\nliveness detection, face spooﬁng, keras and tensorﬂow.\\nI. I NTRODUCTION\\nFace recognition is a biometric system that is working on\\ntaking features from someone’s face then it compares these\\nfeatures with the data of people in a database of known faces.\\nResearchers have developed different methods to recognize\\nthe person’s face and they managed to outcome the obstacles\\nthey faced such as different facial expressions, different angles,\\nand bad illumination. It spreads very rapidly in the last\\ndecade. It has been used in many ﬁelds such as mobile device\\nauthentication [1], payments, companies used face recognition\\nin attendance systems, also used in forensics and security\\naccess [2].\\nOne of the problems that is facing developers when im-\\nplementing a face recognition system is Face spooﬁng. Face\\nspooﬁng is when an attacker tries to breach a face recognition\\nsystem. The most famous face spooﬁng ways are printed\\nimages, Videos, and 3D Masks as shown in Figure (1) which\\nan attacker can gain an illegal access to an authorized person\\nand breach the face recognition system. Face spooﬁng was\\nmentioned for the ﬁrst time as a potential threat for face\\nbiometric systems was by Hoogsteden in 1992. After that, a\\ndetailed study was given by Doctor Stephanie A. C. Schuck-\\ners in 2002 on spooﬁng and anti-spooﬁng [3]. K.Kollreider\\nproposed that in 2005 the structure tensor of the face image\\nis the ﬁrst technique that the liveness detection based on. The\\nliterature survey indicates that since 2005 face spooﬁng has\\nshown a great interest through the researcher’s community as\\nshown in Figure (2). As a result that, since 2010 developers\\nand researchers have been trying to develop a method that\\nprotects face recognition systems from face spooﬁng attacks.\\nFig. 1: Face spooﬁng types [3]\\nFace liveness detection is one of many methods that are\\nused to prevent face spooﬁng attacks. It is relatively new to\\nsense face liveness since the common security methods are\\nﬁngerprints and passwords. However, many companies are in\\na bad need to detect face spooﬁng in order to prevent any\\nillegal access to their systems. Cheaters can gain illegal access\\nby showing an image (or a video or 3D-mask) of an authorized\\nperson standing in front of the security camera. The role of\\nthe security system is to offer access to the faces that belong\\nto living persons. Therefore, detecting face liveness will play\\nan important role in preventing face spooﬁng attacks.\\n978-0-7381-4394-1/21/$31.00 ©2021 IEEE\\n1483\\n2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC) | 978-1-6654-1490-6/21/$31.00 ©2021 IEEE | DOI: 10.1109/CCWC51732.2021.9376030\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            " Document(id_='34242f58-bca2-4ee9-8f36-097b760e1825', embedding=None, metadata={'page_label': '2', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Fig. 2: Face spooﬁng researches [3]\\nThe approach is done using a dataset called CelebA Anti\\nspooﬁng dataset. It is new dataset that is published in 2020. It\\nconsists of 625,537 pictures of 10,177 subjects. So, It is big\\nenough to train on and to have a very good results from it.\\nWe used 2000 pictures for training and 200 for testing. We put\\nin consideration that the used dataset is balanced to prevent\\noverﬁtting and to get the best results possible.\\nOur experiment is done using sequential CNN. So, It will\\nbe divided into several parts. First is the pre-processing part\\nwhich is responsible of the part of feature extraction. Then\\naugmentation will be done. Then the data will be passed to\\nthe CNN layers to train. After that the model will be able to\\nclassify whether the image is live or spoof. Cross-V alidation\\nis also used to test the model’s ability to predict new data\\nthat was not used in estimating it in order to mark problems\\nthat can happen in the model like overﬁtting or selection bias.\\nII. R\\nELA TED WORK\\nFace liveness detection is an important task to prevent the\\nface spooﬁng problem, many approaches have been proposed\\nthat used traditional machine learning algorithms and deep\\nlearning algorithms to address the problem of face spooﬁng,\\nmachine learning consists of sequential steps including pro-\\ncessing, segmentation, feature extraction, and classiﬁcations.\\nTraditional machine learning is applied to face images to\\nextract features such as support vector machine (SVM) [4]\\nand viola jones algorithm [5] which can achieve good clas-\\nsiﬁcation. However, there are some things that could happen\\nwhen using machine learning such as errors, information loss,\\nand poor results. Therefore, we intend to use deep learning\\ntechniques such as Convolutional neural network (CNN) [6]\\nto get better accuracy and better results.\\nSengur et al. [7], presents a convolutional neural network\\n(CNN) approach to detect face liveness detection and it was\\napplied on the NUAA dataset that was divided into 5761\\nimages for test and 3491 images for train, this model achieved\\nan accuracy of 83.38%. Akbulut et al. [6] presented as shown\\nin ﬁgure 3 below CNN implementation also on the NUAA\\ndataset but they divided the dataset into 5761 images for\\ntest and 1748 images for train and the model achieved an\\naccuracy of 84.04% but when they use the local receptive\\nﬁelds (LRF)-ELM they achieved an accuracy of 76.31% on the\\nsame dataset. Komulainen and Pietikainen [5] used the same\\ndataset NUAA and divided into 3362 test samples and 5761\\ntrain samples but this model used local binary pattern(LBP)\\nbased on micro-texture analysis and this depends on some\\nfeatures such as Gabor wavelet features and Histogram of\\noriented Gradients. This representation makes it easy for them\\nto use fast linear support vector machine (SVM) classiﬁers, the\\nresults of the proposed system are calculated using equal error\\nrate (EER) and area under the curve (AUC). So as a result of\\ntheir work there was an improvement in EER from 2.8% to\\n1.1% and in AUC from 0.995 to 0.999.\\nFig. 3: CNN and LRF-ELM on the NUAA Dataset [6]\\nWen et al. [8] proposed an effective system algorithm based\\non image distortion analysis, the system extract four important\\nfeatures from the IDA feature vector which are blurriness,\\nchromatic moment, specular reﬂection, and color diversity, the\\ndataset they use is the replay attack dataset which consists of\\n1,300 video recordings of both real-access and attack attempts\\nof 50 different subjects, this model achieved an accuracy of\\n(average TPR=90.5% & FAR=0.01). Liu et al. [9] used the\\nsame dataset Replay-attack but they use a Deep tree network\\n(DTN) algorithm as shown in Figure 4 below, as it results for\\nan overall accuracy of 95.5%. The Replay-attack dataset was\\nused by Ito et al. [4] as they use the CNN algorithm to extract\\nfeatures from images and classiﬁed them into real and fake by\\nsupport vector machine (SVM), the model runs on the Replay-\\nattack dataset that consists of a set of videos sequences taken\\nfrom 50 subjects of both real and fake scenarios. As a result,\\nof that the error rate (EER) of using these methods is 2.3%\\nand 0.75& respectively.\\nGuo et al. [10] proposed a system that can divide virtual fake\\ndata in order to get a solution for the face spooﬁng problem,\\nthe method relies on virtual synthesis then to use CNN to train\\n1484\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            " Document(id_='a495465f-1294-4abe-b9dd-27176c0b278a', embedding=None, metadata={'page_label': '3', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Fig. 4: Deep tree network algorithm [9]\\nthe large scale synthetic spoof samples, for testing, CASIA-\\nMFSD database is used and CASIA-RFS database is used for\\ntraining. So as a result of their work there is a remarkable\\nimprovement over the weak perspective projection with an\\nEER 2.22% and an HTER 1.67%. Moreover, ACER improves\\nfrom 3.33% to 2.22% and Top-1 accuracy rises from 97.78%\\nto 98.61%.\\nPinto et al. [11] presented a new approach is used by using\\na technique that takes advantage of the noise signatures that\\nis generated by the recaptured video, This method also use\\nFourier spectrum followed by the computation of the visual\\nrhythm that captures the noise that is produced from the\\nrecorded videos. The used dataset in this paper is the Print\\nAttack Database. It consists of 200 videos of 50 different users\\nand 200 videos of spoof attacks. Our criticize for this paper is\\nthat they need to test their approach on larger video databases.\\nIII. S\\nYSTEM ARCHITECTURE\\nThe proposed model uses the sequential deep learning\\narchitecture in which layers of convolution and pooling are\\nstacked from input to output. Figure 5 shows the proposed\\nsystem architecture. The system consists of the following\\nstages:\\nA. input data preprocessing stage\\nData augmentation [13] is a crucial part in training deep\\nnetworks because they need large amounts of data to achieve\\nhigh accuracy. Therefore, multiple augmentation techniques\\nare applied, including shear range, zoom range, and horizontal\\nﬂip as shown in ﬁgure (6).\\nB. feature extraction [14] stage\\nThe proposed CNN architecture consists of two operations:\\nconvolution operation, maxpooling and relu operations, which\\nare repeated three times as shown in ﬁgure 5.\\n• convolution operation: Filters of size (3X3) are passed\\nover the input images of size (150x150) to obtain the\\nFig. 5: proposed system architecture [12]\\nfeatures that are important for classifying input images\\nand discard the features that are not. In other words, ﬁlters\\nconvolve the images.\\n• maxpooling operation: this operation performs feature\\nreduction on the output of the convolution layer, while\\npreserving the unique features of images.\\n• relu activation function: relu function pseudo code can\\nbe represented by a simple if statement as follows:\\nif input >0 then\\nreturn input\\nelse\\nreturn0\\nend if\\nThe function relu converts all negative inputs to zeros to\\n1485\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            " Document(id_='9bc18b38-fa59-4742-bd0d-2d9eb9ba48e2', embedding=None, metadata={'page_label': '4', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Fig. 6: Zoom augmentation results\\nappear as dots in the manipulated images. That makes\\nimages becomes clearer.\\nC. classiﬁcation stage\\n• ﬂatten layer: the function of this layer is to structure the\\nfeature maps into a single vector suitable to be processed\\nby the next neural network layer.\\n• dense and relu activation function: dense function in keras\\nbuilds a neural network with a speciﬁc number of hidden\\nnodes and a relu activation function. It takes the ﬂattened\\nvector to be as an input to the neural network.\\n• dropout: its function is to prevent overﬁtting.\\n• dense and sigmoid activation function: it constitutes the\\noutput layer with sigmoid function since it is a binary\\nclassiﬁcation problem (live or non\\nlive face)\\nD. compiling the CNN\\nto compile the constructed CNN, the function compile is\\nused with three parameters: the optimizer is rmsprop, the\\nloss function is binary\\ncrossentropy and the performance\\nmetric is accuracy. The optimizer rmsprop is an adaptive\\nlearning rate method proposed in [15]. The calculation of\\nbinary\\ncrossentropy loss function is shown in equation 1\\nLoss = − 1\\noutput\\noutput∑\\nsize\\nyi ·log ˆyi +(1 − yi)·log(1 − ˆyi) (1)\\nwhere ˆyi is the i -th scalar value in the model output,yi is\\nthe corresponding target value, and output size is the number\\nof scalar values in the model output. The accuracy is calculated\\nas shown in equation 2\\nAccuracy = (TP+TN)/(TP+TN+FP+FN) (2)\\nIV . E\\nXPERIMENTAL RESULTS\\nThis section introduces the outcome of the experiments\\nperformed using a sequential CNN as described in the previous\\nsection.\\nA. Setup of the Experiment\\nThe experiments were done on a machine equipped with\\nan Intel Core i7-4790 @ 3.6GHZ, 16GB of memory, and\\nan NVIDIA GTX1060 GPU card. The machine runs on\\nWindows10. The experiments were done using python pro-\\ngramming language and keras framework. The experiment\\nwere done using a dataset called CelebA dataset. 2000 pictures\\nwere used for training and 200 pictures were used for testing\\ndivided equally between live and spoof to be balanced.\\nB. Dataset description\\nA novel anti-spooﬁng dataset CelebA-Spoof has been col-\\nlected to recognize live and non-live faces [16]. The main\\nadvantages of CelebA-Spoof are the following:\\n• Quantity: CelebA-Spoof contains 625,537 pictures of\\n10,177 subjects, which is larger than any existing dataset\\nrelated to this ﬁeld.\\n• Diversity: The spoofed images are taken from 8 scenes\\n(2 environments * 4 illumination conditions) with more\\nthan 10 sensors.\\n• Annotation Richness: CelebA-Spoof contains 10 spoof\\ntype annotations, as well as the 40 attribute annotations\\ninherited from the original CelebA dataset [17]\\n• Date: The dataset was made and published in 2020 and\\nit is the newest dataset related to this ﬁeld.\\nThe proposed model is Sequential CNN. It has been tested\\nand cross validated using a part of CelebA-Spoof dataset.\\nC. Training and testing\\nThe data set has been read using ImageDataGenerator [18]\\nwhich is Keras function that will be used in ﬁt generator\\nfunction of the sequential model in Keras that is used for\\ntraining images. The ImageDataGenerator generates classes\\nautomatically from the number of folders existing in the path\\ngiven to it and ﬁt generator [18] function knows how to work\\nwith the information given. This is used in case of testing.\\nImageDataGenerator is also used in augmentation [13]\\npart to increase the size of the training data and to avoid\\noverﬁtting. Augmentation methods used are rescale to make\\nnormalization, Shear to make the image distorted along an\\naxis, zoom to put in consideration the distance from the camera\\nto the face, and horizontal ﬂip.\\nIn cross-validation, we could not use ImageDataGenerator\\nwith K-Fold methods to dividing the dataset into train and\\ntest randomly each time with a different output of images each\\ntime. So, We had to convert the object of ImageDataGenerator\\nthat contains the dataset into two arrays. The ﬁrst array\\ncontains the images as an array of pixels 3 channels for each\\nand the other array contains the label for each image which\\nrepresents its class whether live or spoof. Then it has been\\nsent to a loop of K-fold time in our case 5 times every time\\n1486\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            " Document(id_='d7ec1252-c99b-4882-94e2-ddd1dc4e3ac4', embedding=None, metadata={'page_label': '5', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='TABLE I: Evaluation Measures Results\\nModel Type Measure\\nAccuracy Precision Recall F-measure\\nCNN Train 96.9% 96.9% 96.4% 88.2%\\nNaive Bayes 80.2% 76.6% 78.2% 82.3%\\nCNN Test 87% 93.6% 78.2% 86.8%\\nNaive Bayes 81.2% 78.2% 83.0% 83.2%\\nCNN Cross-V alidation 94.7% 50.9% 81.9% 52.9%\\nNaive Bayes 82% 79.6% 86.3% 83.4%\\nthere is a new test and train set of images divided by the k\\nfold function and then it has been tested using ﬁt function.\\nThen in both ways normal and cross-validation we used the\\nevaluate function to test our model with a totally different set\\nof images.\\nD. Training and testing Results\\nThe dataset is divided into 2000 images for training and 200\\nimages for testing. The number of epochs is 50. We used 50\\nepochs to train the model. Figure 7 shows the test accuracy\\nand the loss per epoch. It is noticed that the accuracy increases\\nand the loss decreases. ROC Curve [19] is produced also as\\nshown in the ﬁgure 8. The area under curve is 0.535.\\nFig. 7: Testing accuracy and loss per epoch\\nFig. 8: ROC curve for testing\\nE. Cross V alidation results\\nWe used 5-Fold Cross V alidation as shown in ﬁgure 9.\\nFig. 9: cross validation accuracy and loss per epoch\\nTable (I) shows the accuracy, precision, recall, and F1-\\nmeasure of training, testing, and cross-validation. The results\\nshow an accuracy of 87% during testing while it shows\\nan accuracy of 96.9 % while training and 94.7% during\\ncross-validation. The difference between testing and training\\naccuracy is not that large. However, Other measures (such as\\nprecision, recall, and F1-measure) are higher in testing than in\\ncross-validation. The justiﬁcation is that cross-validation tests\\nthe system on a part of the data that is seen before. The low\\nvalues of precision, recall, and F1-measure indicate that the\\nclassiﬁer needs more data to be well trained during cross-\\nvalidation. Moreover, the holdout cross validation is intended\\nto be used rather than 5 fold cross validation.\\nV. C\\nONCLUSION AND FUTURE WORK\\nMany security systems have taken care of Face liveness\\ndetection to prevent face spooﬁng. The proposed CNN\\napproach achieved a relatively acceptable accuracy for testing\\nwhich is 87% and for cross validation 94.7%. The system\\nconsists of two stages which are the feature extraction stage\\nand the classiﬁcation stage. The dataset used is CelebA-Spoof\\nwhich appears in 2020. The training set contains 2000\\nimages divided into 1000 live and 1000 spoofed to obtain\\na balanced set and the testing set contains 200 images.\\nHowever, many new techniques are intended to be used in\\nfuture work such as capsule neural networks [20] . Other\\nmodels of CNN such as pre-trained ones will be compared\\nwith regular CNN to achieve the highest performance.\\nAnother type of face spooﬁng will be used like videos\\nusing deep learning algorithms to detect face spooﬁng in\\nvideos such as RNN which is an important face spooﬁng topic.\\n1487\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
            " Document(id_='f8037f2d-dad5-48fe-810d-a5fb2d4bbacd', embedding=None, metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='REFERENCES\\n[1] G. Hassan and K. Elgazzar, “The case of face recognition on mobile\\ndevices,” 2016.\\n[2] D. N. Parmar and B. B. Mehta, “Face recognition methods & applica-\\ntions,” arXiv preprint arXiv:1403.0485, vol. 4, 2013.\\n[3] J. K. Sandeep Kumar and S. Singh, “A comparative study on face spoof-\\ning attacks,” International Conference on Computing, Communication\\nand Automation (ICCCA), 2017.\\n[4] T. O. Koichi Ito and T. Aoki, “Recent advances in biometric security: A\\ncase study of liveness detection in face recognition,”Asia-Paciﬁc Signal\\nand Information Processing Association Annual Summit and Conference\\n(APSIPA ASC), 2017.\\n[5] J. Komulainen and M. Pietikainen, “Face spooﬁng detection from single\\nimages using texture and local shape analysis,”International Conference\\non Computing, Communication and Automation (ICCCA), vol. 1, pp. 3–\\n10, 2012.\\n[6] B. Yaman Akbulut, Abdulkadir Sengur and S. Ekici, “Deep learning\\nbased face liveness detection in videos,”international Artiﬁcial Intelli-\\ngence and Data Processing Symposium (IDAP), 2017.\\n[7] Y . A. Abdulkadir Sengur, Zahid Akhtar and S. Ekici, “Deep feature\\nextraction for face liveness detection,” International Conference on\\nArtiﬁcial Intelligence and Data Processing (IDAP), 2018.\\n[8] H. H. Di Wen and A. K. Jaini, “Face spoof detection with image\\ndistortion analysis,” IEEE Transactions on Information F orensics and\\nSecurity, vol. 10, 2015.\\n[9] A. J. Yaojie Liu, Joel Stehouwer and X. Liu, “Deep tree learning\\nfor zero-shot face anti-spooﬁng,” IEEE/CVF Conference on Computer\\nVision and Pattern Recognition (CVPR), 2019.\\n[10] J. X. Jianzhu Guo, Xiangyu Zhu and S. Z. Li, “Improving face anti-\\nspooﬁng by 3d virtual synthesis,”International Conference on Biomet-\\nrics (ICB), 2019.\\n[11] W. R. S. Allan da Silva Pinto, Helio Pedrini and A. Rocha, “Video-based\\nface spooﬁng detection through visual rhythm analysis,”25th SIBGRAPI\\nConference on Graphics, Patterns and Images, 2012.\\n[12] J. H. M. T. Husein Perez and A. Mosavi, “Deep learning for detecting\\nbuilding defects using convolutional neural networks,” IEEE Transac-\\ntions on Geoscience and Remote Sensing, vol. 54, 2019.\\n[13] L. Perez and J. Wang, “The effectiveness of data augmentation in image\\nclassiﬁcation using deep learning,” vol. 143, 2017.\\n[14] C. L. Y ushi Chen, Hanlu Jiang and X. Jia, “Deep feature extraction\\nand classiﬁcation of hyperspectral images based on convolutional neural\\nnetworks,” 2016.\\n[15] Y . Bengio and M. CA, “Rmsprop and equilibrated adaptive learning\\nrates for nonconvex optimization,”corr abs/1502.04390, 2015.\\n[16] Y . Zhang, Z. Yin, Y . Li, G. Yin, J. Yan, J. Shao, and Z. Liu, “Celeba-\\nspoof: Large-scale face anti-spooﬁng dataset with rich annotations,”\\narXiv preprint arXiv:2007.12342, 2020.\\n[17] Z. Liu, P . Luo, X. Wang, and X. Tang, “Large-scale celebfaces attributes\\n(celeba) dataset,” Retrieved August, vol. 15, p. 2018, 2018.\\n[18] A. Gulli and S. Pal, Deep Learning with Keras. Packt Publishing Ltd,\\n2017.\\n[19] J. A. Hanley and B. J. McNeil, “The meaning and use of the area under\\na receiver operating characteristic (roc) curve,” vol. 143, 1982.\\n[20] J. Y . Huy H. Nguyen and I. Echizen, “Use of a capsule network to detect\\nfake images and videos,” 2019.\\n1488\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORM"
      ],
      "metadata": {
        "id": "PxnakNX37Pd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hide sm keys from llm\n",
        "documents[0].__dict__  # too much data abt one doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MsnNFPOe6ut_",
        "outputId": "f6dc93df-1b2d-425b-d6e4-d732f9161fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id_': '9a7eee2b-f46f-440a-a9ac-5f3e546fc72f',\n",
              " 'embedding': None,\n",
              " 'metadata': {'page_label': '1',\n",
              "  'file_name': 'mohamed2021.pdf',\n",
              "  'file_path': '/content/data/mohamed2021.pdf',\n",
              "  'file_type': 'application/pdf',\n",
              "  'file_size': 528244,\n",
              "  'creation_date': '2025-06-08',\n",
              "  'last_modified_date': '2025-06-08'},\n",
              " 'excluded_embed_metadata_keys': ['file_name',\n",
              "  'file_type',\n",
              "  'file_size',\n",
              "  'creation_date',\n",
              "  'last_modified_date',\n",
              "  'last_accessed_date'],\n",
              " 'excluded_llm_metadata_keys': ['file_name',\n",
              "  'file_type',\n",
              "  'file_size',\n",
              "  'creation_date',\n",
              "  'last_modified_date',\n",
              "  'last_accessed_date'],\n",
              " 'relationships': {},\n",
              " 'metadata_template': '{key}: {value}',\n",
              " 'metadata_separator': '\\n',\n",
              " 'text_resource': MediaResource(embeddings=None, data=None, text='Face Liveness Detection Using a sequential CNN\\ntechnique\\nAbdelrahamn Ashraf Mohamed, Marwan Mohamed Nagah, Mohamed Gamal Abdelmonem,\\nMohamed Yasser Ahmed, Mahmoud El-Sahhar, Fatma Helmy Ismail\\nFaculty of Computer Science\\nMisr International University, Cario, Egypt\\nabdelrahman1711335, marwan1709805, mohamed1709263,\\nmohamed1709620, mahmoud.ezzat, fatma.helmy {@miuegypt.edu.eg}\\nAbstract—One of the most widely used biometric approaches\\nis face recognition. Face recognition is used in many Fields.\\nOne of these ﬁelds is mobile devices authentication. While the\\nnumber of mobile device users increasing year after year, the\\nneed for mobile security is also gaining ground. However, face\\nrecognition can be easily attacked by a malicious face spooﬁng.\\nThat is intended to deceive the face recognition system by facial\\npictures obtained from images or videos. Other cheaters show\\nthe mask of an authorized person to fool the recognition camera\\ninto a real person. Liveness detection is an important research\\ntopic to detect face spooﬁng. The proposed approach in this\\npaper is a deep learning technique which is a sequential CNN\\n(convolution Neural Network) divided into a feature extraction\\nstage and a classiﬁcation stage. The dataset used is CelebA-\\nSpoof (2020) collected to recognize live and non-live faces. The\\nexperiment is performed on a part of the CelebA-Spoof dataset.\\nThe performance of the proposed approach is measured in terms\\nof accuracy. The accuracy of testing the system on unseen data\\nis 87% and the area under ROC curve is 0.535. there are many\\nnew techniques are intended to be used in future work such as\\ncapsule neural networks is expected to improves our results.\\nIndex T erms—deep learning, convolution neural network, face\\nliveness detection, face spooﬁng, keras and tensorﬂow.\\nI. I NTRODUCTION\\nFace recognition is a biometric system that is working on\\ntaking features from someone’s face then it compares these\\nfeatures with the data of people in a database of known faces.\\nResearchers have developed different methods to recognize\\nthe person’s face and they managed to outcome the obstacles\\nthey faced such as different facial expressions, different angles,\\nand bad illumination. It spreads very rapidly in the last\\ndecade. It has been used in many ﬁelds such as mobile device\\nauthentication [1], payments, companies used face recognition\\nin attendance systems, also used in forensics and security\\naccess [2].\\nOne of the problems that is facing developers when im-\\nplementing a face recognition system is Face spooﬁng. Face\\nspooﬁng is when an attacker tries to breach a face recognition\\nsystem. The most famous face spooﬁng ways are printed\\nimages, Videos, and 3D Masks as shown in Figure (1) which\\nan attacker can gain an illegal access to an authorized person\\nand breach the face recognition system. Face spooﬁng was\\nmentioned for the ﬁrst time as a potential threat for face\\nbiometric systems was by Hoogsteden in 1992. After that, a\\ndetailed study was given by Doctor Stephanie A. C. Schuck-\\ners in 2002 on spooﬁng and anti-spooﬁng [3]. K.Kollreider\\nproposed that in 2005 the structure tensor of the face image\\nis the ﬁrst technique that the liveness detection based on. The\\nliterature survey indicates that since 2005 face spooﬁng has\\nshown a great interest through the researcher’s community as\\nshown in Figure (2). As a result that, since 2010 developers\\nand researchers have been trying to develop a method that\\nprotects face recognition systems from face spooﬁng attacks.\\nFig. 1: Face spooﬁng types [3]\\nFace liveness detection is one of many methods that are\\nused to prevent face spooﬁng attacks. It is relatively new to\\nsense face liveness since the common security methods are\\nﬁngerprints and passwords. However, many companies are in\\na bad need to detect face spooﬁng in order to prevent any\\nillegal access to their systems. Cheaters can gain illegal access\\nby showing an image (or a video or 3D-mask) of an authorized\\nperson standing in front of the security camera. The role of\\nthe security system is to offer access to the faces that belong\\nto living persons. Therefore, detecting face liveness will play\\nan important role in preventing face spooﬁng attacks.\\n978-0-7381-4394-1/21/$31.00 ©2021 IEEE\\n1483\\n2021 IEEE 11th Annual Computing and Communication Workshop and Conference (CCWC) | 978-1-6654-1490-6/21/$31.00 ©2021 IEEE | DOI: 10.1109/CCWC51732.2021.9376030\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply. ', path=None, url=None, mimetype=None),\n",
              " 'image_resource': None,\n",
              " 'audio_resource': None,\n",
              " 'video_resource': None,\n",
              " 'text_template': '{metadata_str}\\n\\n{content}'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FORMATTING THE METADATA"
      ],
      "metadata": {
        "id": "I2bY_SBhAqYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "from llama_index.core.schema import MetadataMode\n",
        "\n",
        "document = Document(\n",
        "    text = \"this is a super customized doc\",\n",
        "    metadata = {\n",
        "        \"file_name\" : \"super_secret_document.txt\",\n",
        "         \"category\": \"finance\",\n",
        "        \"author\": \"LlamaIndex\",\n",
        "    },\n",
        "    excluded_embed_metadata_keys=[\"file_name\"],\n",
        "    #excluded_llm_metadata_keys=[\"category\"],\n",
        "    #metadata_seperator=\"\\n\",\n",
        "    metadata_template=\"{key}:{value}\",\n",
        "    text_template=\"Metadata:\\n{metadata_str}\\n-----\\nContent:\\n{content}\",\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"The LLM sees this: \\n\",\n",
        "    document.get_content(metadata_mode=MetadataMode.LLM),\n",
        ")\n",
        "print(\n",
        "   \"The Embedding model sees this: \\n\",\n",
        "     document.get_content(metadata_mode=MetadataMode.EMBED),\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6hJQj7a9p8a",
        "outputId": "a340252e-0549-4036-a2d2-9f996e1cd4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The LLM sees this: \n",
            " Metadata:\n",
            "file_name:super_secret_document.txt\n",
            "category:finance\n",
            "author:LlamaIndex\n",
            "-----\n",
            "Content:\n",
            "this is a super customized doc\n",
            "The Embedding model sees this: \n",
            " Metadata:\n",
            "category:finance\n",
            "author:LlamaIndex\n",
            "-----\n",
            "Content:\n",
            "this is a super customized doc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.schema import MetadataMode\n",
        "\n",
        "# print(documents[1].get_content(metadata_mode=MetadataMode.LLM))   # what the llm sees\n",
        "print(documents[1].get_content(metadata_mode=MetadataMode.EMBED)) # what embeddings see. in this case, same thing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K5NmGoahBuOY",
        "outputId": "42499f39-44a1-45df-8f28-bf0106e71315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_label: 2\n",
            "file_path: /content/data/mohamed2021.pdf\n",
            "\n",
            "Fig. 2: Face spooﬁng researches [3]\n",
            "The approach is done using a dataset called CelebA Anti\n",
            "spooﬁng dataset. It is new dataset that is published in 2020. It\n",
            "consists of 625,537 pictures of 10,177 subjects. So, It is big\n",
            "enough to train on and to have a very good results from it.\n",
            "We used 2000 pictures for training and 200 for testing. We put\n",
            "in consideration that the used dataset is balanced to prevent\n",
            "overﬁtting and to get the best results possible.\n",
            "Our experiment is done using sequential CNN. So, It will\n",
            "be divided into several parts. First is the pre-processing part\n",
            "which is responsible of the part of feature extraction. Then\n",
            "augmentation will be done. Then the data will be passed to\n",
            "the CNN layers to train. After that the model will be able to\n",
            "classify whether the image is live or spoof. Cross-V alidation\n",
            "is also used to test the model’s ability to predict new data\n",
            "that was not used in estimating it in order to mark problems\n",
            "that can happen in the model like overﬁtting or selection bias.\n",
            "II. R\n",
            "ELA TED WORK\n",
            "Face liveness detection is an important task to prevent the\n",
            "face spooﬁng problem, many approaches have been proposed\n",
            "that used traditional machine learning algorithms and deep\n",
            "learning algorithms to address the problem of face spooﬁng,\n",
            "machine learning consists of sequential steps including pro-\n",
            "cessing, segmentation, feature extraction, and classiﬁcations.\n",
            "Traditional machine learning is applied to face images to\n",
            "extract features such as support vector machine (SVM) [4]\n",
            "and viola jones algorithm [5] which can achieve good clas-\n",
            "siﬁcation. However, there are some things that could happen\n",
            "when using machine learning such as errors, information loss,\n",
            "and poor results. Therefore, we intend to use deep learning\n",
            "techniques such as Convolutional neural network (CNN) [6]\n",
            "to get better accuracy and better results.\n",
            "Sengur et al. [7], presents a convolutional neural network\n",
            "(CNN) approach to detect face liveness detection and it was\n",
            "applied on the NUAA dataset that was divided into 5761\n",
            "images for test and 3491 images for train, this model achieved\n",
            "an accuracy of 83.38%. Akbulut et al. [6] presented as shown\n",
            "in ﬁgure 3 below CNN implementation also on the NUAA\n",
            "dataset but they divided the dataset into 5761 images for\n",
            "test and 1748 images for train and the model achieved an\n",
            "accuracy of 84.04% but when they use the local receptive\n",
            "ﬁelds (LRF)-ELM they achieved an accuracy of 76.31% on the\n",
            "same dataset. Komulainen and Pietikainen [5] used the same\n",
            "dataset NUAA and divided into 3362 test samples and 5761\n",
            "train samples but this model used local binary pattern(LBP)\n",
            "based on micro-texture analysis and this depends on some\n",
            "features such as Gabor wavelet features and Histogram of\n",
            "oriented Gradients. This representation makes it easy for them\n",
            "to use fast linear support vector machine (SVM) classiﬁers, the\n",
            "results of the proposed system are calculated using equal error\n",
            "rate (EER) and area under the curve (AUC). So as a result of\n",
            "their work there was an improvement in EER from 2.8% to\n",
            "1.1% and in AUC from 0.995 to 0.999.\n",
            "Fig. 3: CNN and LRF-ELM on the NUAA Dataset [6]\n",
            "Wen et al. [8] proposed an effective system algorithm based\n",
            "on image distortion analysis, the system extract four important\n",
            "features from the IDA feature vector which are blurriness,\n",
            "chromatic moment, specular reﬂection, and color diversity, the\n",
            "dataset they use is the replay attack dataset which consists of\n",
            "1,300 video recordings of both real-access and attack attempts\n",
            "of 50 different subjects, this model achieved an accuracy of\n",
            "(average TPR=90.5% & FAR=0.01). Liu et al. [9] used the\n",
            "same dataset Replay-attack but they use a Deep tree network\n",
            "(DTN) algorithm as shown in Figure 4 below, as it results for\n",
            "an overall accuracy of 95.5%. The Replay-attack dataset was\n",
            "used by Ito et al. [4] as they use the CNN algorithm to extract\n",
            "features from images and classiﬁed them into real and fake by\n",
            "support vector machine (SVM), the model runs on the Replay-\n",
            "attack dataset that consists of a set of videos sequences taken\n",
            "from 50 subjects of both real and fake scenarios. As a result,\n",
            "of that the error rate (EER) of using these methods is 2.3%\n",
            "and 0.75& respectively.\n",
            "Guo et al. [10] proposed a system that can divide virtual fake\n",
            "data in order to get a solution for the face spooﬁng problem,\n",
            "the method relies on virtual synthesis then to use CNN to train\n",
            "1484\n",
            "Authorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in documents:\n",
        "    # define the content/metadata template\n",
        "    doc.text_template = \"Metadata:\\n{metadata_str}\\n---\\nContent:\\n{content}\"\n",
        "\n",
        "    # exclude page label from embedding\n",
        "    if \"page_label\" not in doc.excluded_embed_metadata_keys:\n",
        "        doc.excluded_embed_metadata_keys.append(\"page_label\")"
      ],
      "metadata": {
        "id": "Sa4ZruOaC6Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after editing the content seen by embedings\n",
        "\n",
        "print(documents[1].get_content(metadata_mode=MetadataMode.EMBED))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hDnj_zDxDYW5",
        "outputId": "7d5f6c16-bae3-4028-dc62-2785f46d9af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata:\n",
            "file_path: /content/data/mohamed2021.pdf\n",
            "---\n",
            "Content:\n",
            "Fig. 2: Face spooﬁng researches [3]\n",
            "The approach is done using a dataset called CelebA Anti\n",
            "spooﬁng dataset. It is new dataset that is published in 2020. It\n",
            "consists of 625,537 pictures of 10,177 subjects. So, It is big\n",
            "enough to train on and to have a very good results from it.\n",
            "We used 2000 pictures for training and 200 for testing. We put\n",
            "in consideration that the used dataset is balanced to prevent\n",
            "overﬁtting and to get the best results possible.\n",
            "Our experiment is done using sequential CNN. So, It will\n",
            "be divided into several parts. First is the pre-processing part\n",
            "which is responsible of the part of feature extraction. Then\n",
            "augmentation will be done. Then the data will be passed to\n",
            "the CNN layers to train. After that the model will be able to\n",
            "classify whether the image is live or spoof. Cross-V alidation\n",
            "is also used to test the model’s ability to predict new data\n",
            "that was not used in estimating it in order to mark problems\n",
            "that can happen in the model like overﬁtting or selection bias.\n",
            "II. R\n",
            "ELA TED WORK\n",
            "Face liveness detection is an important task to prevent the\n",
            "face spooﬁng problem, many approaches have been proposed\n",
            "that used traditional machine learning algorithms and deep\n",
            "learning algorithms to address the problem of face spooﬁng,\n",
            "machine learning consists of sequential steps including pro-\n",
            "cessing, segmentation, feature extraction, and classiﬁcations.\n",
            "Traditional machine learning is applied to face images to\n",
            "extract features such as support vector machine (SVM) [4]\n",
            "and viola jones algorithm [5] which can achieve good clas-\n",
            "siﬁcation. However, there are some things that could happen\n",
            "when using machine learning such as errors, information loss,\n",
            "and poor results. Therefore, we intend to use deep learning\n",
            "techniques such as Convolutional neural network (CNN) [6]\n",
            "to get better accuracy and better results.\n",
            "Sengur et al. [7], presents a convolutional neural network\n",
            "(CNN) approach to detect face liveness detection and it was\n",
            "applied on the NUAA dataset that was divided into 5761\n",
            "images for test and 3491 images for train, this model achieved\n",
            "an accuracy of 83.38%. Akbulut et al. [6] presented as shown\n",
            "in ﬁgure 3 below CNN implementation also on the NUAA\n",
            "dataset but they divided the dataset into 5761 images for\n",
            "test and 1748 images for train and the model achieved an\n",
            "accuracy of 84.04% but when they use the local receptive\n",
            "ﬁelds (LRF)-ELM they achieved an accuracy of 76.31% on the\n",
            "same dataset. Komulainen and Pietikainen [5] used the same\n",
            "dataset NUAA and divided into 3362 test samples and 5761\n",
            "train samples but this model used local binary pattern(LBP)\n",
            "based on micro-texture analysis and this depends on some\n",
            "features such as Gabor wavelet features and Histogram of\n",
            "oriented Gradients. This representation makes it easy for them\n",
            "to use fast linear support vector machine (SVM) classiﬁers, the\n",
            "results of the proposed system are calculated using equal error\n",
            "rate (EER) and area under the curve (AUC). So as a result of\n",
            "their work there was an improvement in EER from 2.8% to\n",
            "1.1% and in AUC from 0.995 to 0.999.\n",
            "Fig. 3: CNN and LRF-ELM on the NUAA Dataset [6]\n",
            "Wen et al. [8] proposed an effective system algorithm based\n",
            "on image distortion analysis, the system extract four important\n",
            "features from the IDA feature vector which are blurriness,\n",
            "chromatic moment, specular reﬂection, and color diversity, the\n",
            "dataset they use is the replay attack dataset which consists of\n",
            "1,300 video recordings of both real-access and attack attempts\n",
            "of 50 different subjects, this model achieved an accuracy of\n",
            "(average TPR=90.5% & FAR=0.01). Liu et al. [9] used the\n",
            "same dataset Replay-attack but they use a Deep tree network\n",
            "(DTN) algorithm as shown in Figure 4 below, as it results for\n",
            "an overall accuracy of 95.5%. The Replay-attack dataset was\n",
            "used by Ito et al. [4] as they use the CNN algorithm to extract\n",
            "features from images and classiﬁed them into real and fake by\n",
            "support vector machine (SVM), the model runs on the Replay-\n",
            "attack dataset that consists of a set of videos sequences taken\n",
            "from 50 subjects of both real and fake scenarios. As a result,\n",
            "of that the error rate (EER) of using these methods is 2.3%\n",
            "and 0.75& respectively.\n",
            "Guo et al. [10] proposed a system that can divide virtual fake\n",
            "data in order to get a solution for the face spooﬁng problem,\n",
            "the method relies on virtual synthesis then to use CNN to train\n",
            "1484\n",
            "Authorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "APPLYING MORE SOPHISTICATED TRANSFORMATIONS"
      ],
      "metadata": {
        "id": "-GL625vhIabS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are other, more advanced transformations. Some require an LLM to work. We will use Qwen 2.5 32B Instruct 128k through Groq, which is an affordble, high-rate model. It should be enough to extract Q&As and titles from the documents."
      ],
      "metadata": {
        "id": "KF4fA7w9IevU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uq llama-index-llms-groq"
      ],
      "metadata": {
        "id": "jEKP8ZJ6b-qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.groq import Groq\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Groq API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz0s_1KNcKSU",
        "outputId": "29785960-eacc-495d-a558-14f7fddccd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groq API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 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 = groq api key used\n",
        "\n",
        "# initializing the model\n",
        "\n",
        "llm_transformations = Groq(model=\"llama3-8b-8192\", api_key=os.environ[\"GROQ_API_KEY\"])"
      ],
      "metadata": {
        "id": "b-Zn5XXEDpIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the lang model to generate ques and ans\n",
        "\n",
        "# other transformations\n",
        "\n",
        "from llama_index.core.extractors import (\n",
        "    TitleExtractor,\n",
        "    QuestionsAnsweredExtractor,\n",
        ")\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "text_splitter = SentenceSplitter(\n",
        "    separator=\" \", chunk_size=1024, chunk_overlap=128\n",
        ")\n",
        "title_extractor = TitleExtractor(llm=llm_transformations, nodes=5)\n",
        "qa_extractor = QuestionsAnsweredExtractor(llm=llm_transformations, questions=3)\n",
        "\n",
        "\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        text_splitter,\n",
        "        title_extractor,\n",
        "        qa_extractor\n",
        "    ]\n",
        ")\n",
        "\n",
        "nodes = pipeline.run(\n",
        "    documents=documents,\n",
        "    in_place=True,\n",
        "    show_progress=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36ffa21cec33455c9325855101050c8d",
            "fdfb4180ea0c404abee09570a5b71305",
            "88ccf20395774d0b97db2eebf959ac0f",
            "c183aece54a5456ab2470b0f8345b20f",
            "97a13bf736d74640b82336e93019f27a",
            "f51a77be3f3a4764a7e64b36c120c0a2",
            "854af046ea9c4181afe4ab94639ef570",
            "70169928ce734c7b87d4c1ced975b899",
            "293a0de5d19f432c8d5ff316a3e583c2",
            "a2d1140e299b491ead8801260689159c",
            "bbf618aaf0a847f69f4b69471d7b72ee"
          ]
        },
        "id": "DubZ5xzEdGMG",
        "outputId": "f5fd1945-5161-4713-a81e-ee6bb2f76303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36ffa21cec33455c9325855101050c8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 1/2 [00:00<00:00,  2.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.04it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 1/2 [00:00<00:00,  2.93it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.95it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 2/2 [00:00<00:00,  4.31it/s]\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1/1 [00:08<00:00,  8.46s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 1/2 [00:02<00:02,  2.43s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 2/2 [00:12<00:00,  6.35s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|█         | 1/10 [00:10<01:34, 10.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20%|██        | 2/10 [00:23<01:35, 11.98s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 3/10 [00:23<00:46,  6.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 4/10 [00:25<00:29,  4.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50%|█████     | 5/10 [00:32<00:26,  5.37s/it]\u001b[A\u001b[AWARNING:llama_index.llms.openai.utils:Retrying llama_index.llms.openai.base.OpenAI._achat in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama3-8b-8192` in organization `org_01jx86xr75e0w86zgxa0rdvfad` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5518, Requested 1277. Please try again in 7.947s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}.\n",
            "\n",
            "\n",
            " 60%|██████    | 6/10 [00:40<00:25,  6.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 7/10 [00:41<00:13,  4.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80%|████████  | 8/10 [00:41<00:06,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 9/10 [00:41<00:02,  2.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 10/10 [00:58<00:00,  5.85s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, Llamaindex uses OpenAI's embedding models. But you can choose to load a free model from HuggingFace too (but it it will be slower)."
      ],
      "metadata": {
        "id": "bq9Bl6sk28F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6fVFdzLeSp9",
        "outputId": "c60ccaa8-b81a-4fc4-d5a5-76a0ca5814e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "#pprint.pprint(nodes[0].__dict__)\n",
        "\n",
        "print(nodes[0].get_content(metadata_mode = MetadataMode.LLM))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QXnLgwk2eAze",
        "outputId": "d7d6809e-8933-4b06-f810-ba378d8e07bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Excerpt from document]\n",
            "page_label: 1\n",
            "file_path: /content/data/mohamed2021.pdf\n",
            "document_title: Based on the provided information, I would suggest the following comprehensive title:\n",
            "\n",
            "\"Face Liveness Detection and Face Spoofing: A Deep Learning Approach for Mobile Device Authentication and Secure Biometric Systems\"\n",
            "\n",
            "This title captures the main themes and entities mentioned, including face liveness detection, face spoofing, mobile device authentication, deep learning, and biometric systems, while also emphasizing the focus on security and authentication.\n",
            "questions_this_excerpt_can_answer: Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\n",
            "\n",
            "1. What is the accuracy of the proposed sequential CNN approach in detecting face spoofing attacks, and how does it compare to other existing methods?\n",
            "\n",
            "This question can be answered by analyzing the experiment results mentioned in the abstract, specifically the accuracy of 87% and the area under the ROC curve of 0.535.\n",
            "\n",
            "2. What are the most common types of face spoofing attacks, and how have they evolved over time?\n",
            "\n",
            "This question can be answered by analyzing the literature survey mentioned in the introduction, specifically the discussion of face spoofing types and the increasing interest in the topic since 2005.\n",
            "\n",
            "3. What are some potential future directions for improving face liveness detection, and how do they relate to the proposed sequential CNN approach?\n",
            "\n",
            "This question can be answered by analyzing the discussion of future work mentioned in the abstract, specifically the mention of capsule neural networks as a potential technique for improving results.\n",
            "\n",
            "Higher-level summaries of surrounding context that may be useful for generating better questions include:\n",
            "\n",
            "* The context is related to face recognition and biometric systems, and specifically focuses on face liveness detection and face spoofing attacks.\n",
            "* The proposed approach is a deep learning technique using a sequential CNN, and the experiment is performed on a part of the CelebA-Spoof dataset.\n",
            "* The context mentions the importance of face liveness detection in preventing face spoofing attacks, and the need for secure biometric systems in mobile devices and other applications.\n",
            "\n",
            "These summaries can be used to generate more specific and targeted questions that this context can answer.\n",
            "Excerpt:\n",
            "-----\n",
            "Face Liveness Detection Using a sequential CNN\n",
            "technique\n",
            "Abdelrahamn Ashraf Mohamed, Marwan Mohamed Nagah, Mohamed Gamal Abdelmonem,\n",
            "Mohamed Yasser Ahmed, Mahmoud El-Sahhar, Fatma Helmy Ismail\n",
            "Faculty of Computer Science\n",
            "Misr International University, Cario, Egypt\n",
            "abdelrahman1711335, marwan1709805, mohamed1709263,\n",
            "mohamed1709620, mahmoud.ezzat, fatma.helmy {@miuegypt.edu.eg}\n",
            "Abstract—One of the most widely used biometric approaches\n",
            "is face recognition. Face recognition is used in many Fields.\n",
            "One of these ﬁelds is mobile devices authentication. While the\n",
            "number of mobile device users increasing year after year, the\n",
            "need for mobile security is also gaining ground. However, face\n",
            "recognition can be easily attacked by a malicious face spooﬁng.\n",
            "That is intended to deceive the face recognition system by facial\n",
            "pictures obtained from images or videos. Other cheaters show\n",
            "the mask of an authorized person to fool the recognition camera\n",
            "into a real person. Liveness detection is an important research\n",
            "topic to detect face spooﬁng. The proposed approach in this\n",
            "paper is a deep learning technique which is a sequential CNN\n",
            "(convolution Neural Network) divided into a feature extraction\n",
            "stage and a classiﬁcation stage. The dataset used is CelebA-\n",
            "Spoof (2020) collected to recognize live and non-live faces. The\n",
            "experiment is performed on a part of the CelebA-Spoof dataset.\n",
            "The performance of the proposed approach is measured in terms\n",
            "of accuracy. The accuracy of testing the system on unseen data\n",
            "is 87% and the area under ROC curve is 0.535. there are many\n",
            "new techniques are intended to be used in future work such as\n",
            "capsule neural networks is expected to improves our results.\n",
            "Index T erms—deep learning, convolution neural network, face\n",
            "liveness detection, face spooﬁng, keras and tensorﬂow.\n",
            "I. I NTRODUCTION\n",
            "Face recognition is a biometric system that is working on\n",
            "taking features from someone’s face then it compares these\n",
            "features with the data of people in a database of known faces.\n",
            "Researchers have developed different methods to recognize\n",
            "the person’s face and they managed to outcome the obstacles\n",
            "they faced such as different facial expressions, different angles,\n",
            "and bad illumination. It spreads very rapidly in the last\n",
            "decade. It has been used in many ﬁelds such as mobile device\n",
            "authentication [1], payments, companies used face recognition\n",
            "in attendance systems, also used in forensics and security\n",
            "access [2].\n",
            "One of the problems that is facing developers when im-\n",
            "plementing a face recognition system is Face spooﬁng. Face\n",
            "spooﬁng is when an attacker tries to breach a face recognition\n",
            "system. The most famous face spooﬁng ways are printed\n",
            "images, Videos, and 3D Masks as shown in Figure (1) which\n",
            "an attacker can gain an illegal access to an authorized person\n",
            "and breach the face recognition system. Face spooﬁng was\n",
            "mentioned for the ﬁrst time as a potential threat for face\n",
            "biometric systems was by Hoogsteden in 1992. After that, a\n",
            "detailed study was given by Doctor Stephanie A. C. Schuck-\n",
            "ers in 2002 on spooﬁng and anti-spooﬁng [3]. K.Kollreider\n",
            "proposed that in 2005 the structure tensor of the face image\n",
            "is the ﬁrst technique that the liveness detection based on. The\n",
            "literature survey indicates that since 2005 face spooﬁng has\n",
            "shown a great interest through the researcher’s community as\n",
            "shown in Figure (2). As a result that, since 2010 developers\n",
            "and researchers have been trying to develop a method that\n",
            "protects face recognition systems from face spooﬁng attacks.\n",
            "Fig. 1: Face spooﬁng types [3]\n",
            "Face liveness detection is one of many methods that are\n",
            "used to prevent face spooﬁng attacks. It is relatively new to\n",
            "sense face liveness since the common security methods are\n",
            "ﬁngerprints and passwords. However, many companies are in\n",
            "a bad need to detect face spooﬁng in order to prevent any\n",
            "illegal access to their systems. Cheaters can gain illegal access\n",
            "by showing an image (or a video or 3D-mask) of an authorized\n",
            "person standing in front of the security camera.\n",
            "-----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INDEX\n"
      ],
      "metadata": {
        "id": "HZ-TZoDrgV7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embeddings\n",
        "\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "hf_embeddings = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "test_embed = hf_embeddings.get_text_embedding(\"Hello world\")\n",
        "print(test_embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "f980be4fc91a435b8f4ea2a2c4c42815",
            "78b9620d4fbb4887bb8f7c9f23c2818e",
            "ab9ea5cfc90743d5ab9273efe87e00d0",
            "3e170f1b0ab54edabc29b1153335d41a",
            "df2169c7e96642a9b0399e88df0ffb46",
            "139c1b4cfa6e4260b62eeaff1152beec",
            "9bf0b21feab94823b98f0a00829260d4",
            "4b3d7d7850c642539d7933f4eb73cb89",
            "8d7c38a3fda84fb08e06adbfcac2081f",
            "be3c35db15ae4a0ea5b0bf005f92f25e",
            "ee0ff8f1c6b9491fb5510240c573fc26",
            "51c526a15879492a8863e24c63c10051",
            "1950900b4a90426ca9718f661ee3f0e8",
            "04efda97090d4ecd89dd2f6689d54b0f",
            "89fa4c155a4f40b184f11929e352e260",
            "c93c061945e547a0918d15d6d792c729",
            "9cf379caa1b848e98dbd8ad55eca9331",
            "33502cea8efa40019b5baf3a66646ba0",
            "b84d92a5cab24d9092f2ef2b19e24f13",
            "4894d7e5e82b47ecba12507c5387b8a3",
            "5c5bca121ad94e2cab48b86b01b3a501",
            "acd160290ba845a0ba921ec05222c695",
            "d245c61e6a8f42f3827bc14fb15ebc5d",
            "ff84cf7b378548f49a8195ab0d7cc64a",
            "03fa4f8e54bb4402818954f8524ddb53",
            "054d3374c6414c74bb2a48e7ef7d6ca1",
            "f4f0eb65357f44c8a70ed405b68e26a9",
            "59a89944b5ce47ae8638e9f3a0677b77",
            "cf13a5b9186348459b58673e55f7ad77",
            "4f6e99f58a274c82b859702196bb35c5",
            "3b60052b8d1b4764bf6511b79c965106",
            "84af73e650b4474cba16d0437e17cd5a",
            "a81229475c7c492f971fc085ce85f4a9",
            "64e55b7ace8a452b8c5f9c9dc4f7be65",
            "15a1bdded877486288bfc093be686635",
            "234c3bdf518a4407909f01126ab50c7e",
            "6cbaeed821e244ac91c0f99cead49529",
            "4a5605d4a9ef42798134af2929bb1180",
            "7d2849e01db2432e91c02742a7fb2164",
            "75476b2c67c347089fa9315e29574248",
            "85e6be3da67641d2a80c0430495eb9f7",
            "db31663d454d46cb804cb938ccdfc0be",
            "593f73849a0f409fa21a62a003b1e6fd",
            "28bbdb8c53864d6397035de3444d0986",
            "b1e591b4efb341a896e535b243d648ad",
            "1b1c898bc9174c068cee95488275e23a",
            "0a3c476bf2bb4beb9f71ff9a2c1101d7",
            "4a7ef0cdebc84f6bb69420e2b0314d14",
            "65c0c9e0eef34cb0afea1c25abdc3334",
            "94ded352db2b4adf970f05719a934049",
            "b5f6cb59d44f45ba9e9b9811ebf389a2",
            "4d1e0812554f4a48bdd9adf500cf69f6",
            "097af4545c5f47c9b017e23fbccb523f",
            "5b3a1d189459488c998abf597c3e3d40",
            "39177a46d18f4cbfb6c7b36961134aee",
            "078af90ff87549f5bb1f91c5ef0d4799",
            "b4d1fe95777642f6a7b929a7bc497fa6",
            "41616dad3799421086763199d6e28eab",
            "8d36c5d953a74a6494f34642eb3519bd",
            "d971290f87f84ce8999a7ae22ef0c93e",
            "f16a5497720a415a82041e3a1088524e",
            "747665af4d8b4d6c8d98ce1b55f4c4a2",
            "4eaadd4d6a8e4b979d83264435a1e0a1",
            "1ce3ad8d20eb4090a03ae30fc7dc09bd",
            "49deb0d353614295bd9d7a91948c7c59",
            "cdc700d793b047a7a9c58de730119d54",
            "efe0a857fda44d448a0aeba0894fda31",
            "257ce9bd01a140e585a06a0f86bb34ba",
            "2c1b777ded924b03bf14f0a87320a5ca",
            "205dec4acf7f4bebb411a9ca6fd4ad3d",
            "bd9eca4c3472415098486041095a3513",
            "08e0484aeff84bbba964e543ed20487f",
            "0eebe6c8b9ec4fd29c897dfebbb4d0fa",
            "1ecc29e2609c4aa9b9140cbfd44c5968",
            "27386af8ac89442195a9af3e3034ef71",
            "6957cbe905fd4f84b7263c3287609f28",
            "d5449aba229f4089998809a8580dc0fa",
            "4316c34b4b654a6989370622c151535b",
            "3fc9f54f575049b8bf2d88cc522f4db4",
            "cfc4fc21d5be4f26adc8f1b513a00391",
            "2baeb592c82f47b584d6efdc407ef4e4",
            "fd1f69c5c9c541178874ed416799b9ad",
            "35b2c2ed3042486fb08ccb850a9665a8",
            "08788d73f9e044b691b08e41ed06ff82",
            "d9ff45cd8c354cde89e41cdc3dee81a5",
            "ee77ee6750434249abc9b7ebb8f211f8",
            "f25f20e7e0fd4e1fb7688b150a4ddac5",
            "31594aae0a5a4813b1bf0afa80d70efe",
            "745ed88420024dafb272c561e2ce7e9c",
            "b992ab0fbd0043f4be80f352ee8c41b9",
            "b44bf6b2d35a4b1b9fdbc75c552fa618",
            "a6d29c52abf5477188a244cfebcb8cec",
            "7bb4ddd93c9e405b957d2d366dbc243c",
            "82d8f7cc375c4f4282940e897b445090",
            "4463aa81785c46cab72275580862cd47",
            "57c1f24ba3cd4549bd7bee39983d45d5",
            "41ce6c97b26c48e29cb05b2010ea3770",
            "cabe565247f84642b11d7e5d8beef466",
            "ddb2b3acb7bd4fc689ab1b871ec254fa",
            "753b846ac64940d8bd84a5fd3ee2e11e",
            "7b09d53aee6f4c90bb43b9702bdba947",
            "3db58e2b7af149c796b7f15e351335d2",
            "e45a8aa7da434ed08e420e59000046de",
            "a8d066adfb4d4cf989aa072e804c5618",
            "0aaa1679bc614bb090069a7b2e6cfdfe",
            "2b51bab97f804ec79b009a1c8aeb94cc",
            "f8b45e9bc31a426ebdc4ddad63ac519d",
            "b632c62364634643bd81eded98913091",
            "543058cc902a4c7ea4bc08c7f98419f9",
            "be1330a02c134c77b8d345448c6a9b7b",
            "40d8f8cfb60f4dbe8381cb54de8b6e18",
            "2e7d3944fe76457588fa01649c04c4a1",
            "b359c2c41b504b0db995d069b38258ef",
            "f33e695f9872489c9b6c1374789d800f",
            "e21a62ec94814a24aa040b47e4f5b9f0",
            "c57b4f598784461eba930e764cc404cb",
            "f6774bc3907e451fa3a77330bad5fbdd",
            "1849cdfb296942c9a9fb596a5e32d5d5",
            "e7364a0090c5447e9d22b2d4c9a7aa4a",
            "01de4f211cd546f3b364d1320674a209",
            "fae5c9f523df4ce887d477dcb3d83740"
          ]
        },
        "id": "ad6xfgcGfln1",
        "outputId": "e1aac323-f604-4989-bf47-45b6fb828a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f980be4fc91a435b8f4ea2a2c4c42815"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51c526a15879492a8863e24c63c10051"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d245c61e6a8f42f3827bc14fb15ebc5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64e55b7ace8a452b8c5f9c9dc4f7be65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1e591b4efb341a896e535b243d648ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "078af90ff87549f5bb1f91c5ef0d4799"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe0a857fda44d448a0aeba0894fda31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4316c34b4b654a6989370622c151535b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "745ed88420024dafb272c561e2ce7e9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "753b846ac64940d8bd84a5fd3ee2e11e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40d8f8cfb60f4dbe8381cb54de8b6e18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.015196100808680058, -0.022570667788386345, 0.0085471011698246, -0.07417059689760208, 0.0038364154752343893, 0.0027135491836816072, -0.0312679260969162, 0.04463403671979904, 0.044055208563804626, -0.007871134206652641, -0.025200756266713142, -0.033366620540618896, 0.014427922666072845, 0.04653818905353546, 0.008555104956030846, -0.016145728528499603, 0.007405802607536316, -0.01901242695748806, -0.114726223051548, -0.01815761812031269, 0.12635929882526398, 0.02970289997756481, 0.025281012058258057, -0.034217868000268936, -0.04099970683455467, 0.006617335136979818, 0.010270599275827408, 0.022362269461154938, 0.004436342045664787, -0.12730959057807922, -0.0161492470651865, -0.020380133762955666, 0.047212108969688416, 0.011579900048673153, 0.0681871548295021, 0.007298617158085108, -0.017852986231446266, 0.04078212380409241, -0.010269463062286377, 0.023757092654705048, 0.01060289703309536, -0.028584439307451248, 0.00815972313284874, -0.015180555172264576, 0.0308962594717741, -0.06597989052534103, -0.022196460515260696, 0.05402376502752304, 0.002542270114645362, 0.022452717646956444, -0.09165379405021667, -0.0451403371989727, -0.004192073363810778, -0.005621547810733318, -0.005380974616855383, 0.09839349240064621, 0.06052481383085251, 0.007422890048474073, 0.013938630931079388, 0.0026877839118242264, 0.047569386661052704, 0.02863655798137188, -0.1553441733121872, 0.06893698871135712, 0.030248140916228294, -0.017939722165465355, 0.020977122709155083, 0.021408820524811745, 0.014081145636737347, 0.0018777523655444384, 0.002672150731086731, 0.003872342174872756, 0.04116380959749222, 0.06589510291814804, -0.006151887588202953, -0.01646539568901062, 0.008194747380912304, -0.04895549640059471, -0.021113518625497818, -0.030849333852529526, -0.04047700762748718, 0.05926100164651871, 0.018165262416005135, -0.044294215738773346, 0.00070346420397982, -0.02790781483054161, -0.040638748556375504, -0.011253676377236843, -0.024980859830975533, 0.009651386179029942, -0.017492031678557396, -0.0272963996976614, -0.015290319919586182, -0.005397049710154533, -0.041438329964876175, 0.007155391853302717, 0.007107213139533997, 0.009749121963977814, 0.0006180242053233087, 0.34404006600379944, -0.09539391845464706, -0.002025248948484659, 0.028092898428440094, -0.09136314690113068, 0.05958416312932968, 0.024909155443310738, -0.016385599970817566, -0.029118672013282776, -0.00836279895156622, 0.01569259725511074, 0.012841596268117428, -0.06428156793117523, 0.01450104359537363, -0.01374074351042509, 0.0010520146461203694, -0.019681014120578766, 0.050033725798130035, -0.002808474702760577, 0.09320443868637085, -0.029492497444152832, -0.008043671026825905, 0.030725058168172836, -0.043980032205581665, -0.004204513970762491, 0.05286627635359764, -0.06449882686138153, 0.05819977447390556, 0.07761351019144058, 0.011616289615631104, 0.06978410482406616, -0.005409469828009605, 0.05983442813158035, -0.02635258436203003, -0.008660326711833477, 0.027554817497730255, -0.014334382489323616, -0.018221521750092506, -0.01394216250628233, 0.03554501011967659, -0.05676669627428055, 0.008173596113920212, -0.07672377675771713, -0.022576892748475075, -0.11284568160772324, 0.00033895016531459987, 0.030381465330719948, -0.07333746552467346, 0.02454565465450287, -0.019619937986135483, -0.02408602274954319, -0.03893820941448212, 0.07869318127632141, 0.004945841617882252, -0.016329193487763405, 0.007779822684824467, 0.05509072169661522, -0.012773750349879265, 0.06841861456632614, 0.007775839418172836, 0.008763264864683151, -0.0018357591470703483, -0.01243808213621378, -0.013271583244204521, 0.006665409076958895, -0.01779903843998909, -0.12814685702323914, 0.00999290682375431, 0.01943487487733364, -0.007243291009217501, 0.0008530201739631593, 0.0032818184699863195, 0.0165554191917181, -0.039597202092409134, 0.028904233127832413, 0.10964842140674591, 0.007512473035603762, -0.004082219675183296, 0.04457123205065727, -0.04725171998143196, 0.0251011922955513, 0.06009760871529579, -0.05091467127203941, -0.041688285768032074, 0.019089043140411377, 0.028275437653064728, -0.025334294885396957, -0.020802585408091545, -0.030481697991490364, 0.06234196946024895, 0.06707878410816193, -0.023084666579961777, 0.010649421252310276, -0.03191756084561348, -0.03424482420086861, -0.0842171385884285, 0.0033713553566485643, 0.033969730138778687, -0.08108049631118774, 0.013465014286339283, -0.021524466574192047, 0.14621298015117645, 0.05304112657904625, 0.004024832043796778, 0.02876574546098709, 0.0005536453099921346, 0.004209392704069614, 0.040644124150276184, 0.006172468885779381, 0.044874854385852814, 0.013396861031651497, -0.02427598461508751, -0.015174167230725288, 0.07311949133872986, -0.006560380570590496, 0.021938832476735115, -0.042953744530677795, -0.009960728697478771, 0.07461085915565491, 0.023877721279859543, 0.047125622630119324, -0.03976583853363991, 0.010774659924209118, -0.02215058170258999, -0.2623772621154785, 0.018034635111689568, 0.00821615569293499, -0.0034165740944445133, -0.03475773334503174, 0.022967888042330742, 0.03806747868657112, -0.05160956829786301, 0.10182669013738632, -0.009048523381352425, 0.08706744015216827, -0.059638090431690216, -0.008330143988132477, -0.03651220723986626, 0.017570801079273224, 0.02319544367492199, -0.01417655497789383, 0.016011379659175873, -0.010097756050527096, -0.022710023447871208, 0.0286225788295269, 0.02296571061015129, 0.04340478405356407, -0.047622840851545334, 0.044430073350667953, -0.05967703461647034, 0.1465604603290558, 0.08372192829847336, -0.020242953673005104, 0.024193396791815758, 0.03635026514530182, -0.027955906465649605, -0.00928501132875681, -0.11986209452152252, -0.025538818910717964, 0.07363231480121613, -0.034649383276700974, -0.06727728247642517, -0.09658314287662506, -0.022283533588051796, -0.012429878115653992, 0.013772636651992798, -0.04093782603740692, -0.004331015516072512, -0.024142568930983543, -0.07481463253498077, -0.05261692404747009, 0.00980024877935648, -0.05206740275025368, -0.01245517935603857, -0.01169140636920929, 0.022350167855620384, 0.05714461952447891, 0.06000141426920891, 0.019016506150364876, -0.04594934731721878, 0.0016672824276611209, -0.0006488820654340088, -0.011496832594275475, 0.03237846493721008, -0.01466277800500393, -0.022220857441425323, 0.015859408304095268, -0.03663554787635803, 0.011533583514392376, 0.035069677978754044, -0.06106363981962204, -0.024883560836315155, 0.0498194545507431, -0.017432773485779762, -0.01812315359711647, -0.035717155784368515, 0.021230831742286682, -0.01648014411330223, 0.03630692884325981, 0.014197828248143196, -0.004501106683164835, -0.02329937554895878, -0.03982175886631012, -0.028173962607979774, -0.005503776017576456, 0.011411160230636597, 0.058362316340208054, 0.014237262308597565, 0.03271001949906349, 0.054092418402433395, 0.06469085067510605, 0.0077224839478731155, 0.03545178845524788, -0.016053467988967896, -0.01295078918337822, 0.04122379422187805, -0.005376953165978193, -0.06980965286493301, 0.011314000934362411, 0.016101377084851265, -0.29501011967658997, 0.027776727452874184, -0.002964923856779933, 0.021393125876784325, 0.0040660337544977665, 0.02116362750530243, 0.04112172871828079, -0.0004153905319981277, -0.057323042303323746, 0.02231050282716751, -0.07742249965667725, 0.020380832254886627, 0.016258513554930687, -0.06689386069774628, 0.0008157818811014295, 0.020208533853292465, -0.0024550026282668114, -0.011008578352630138, 0.017055975273251534, -0.019496040418744087, 0.0020479673985391855, 0.022157611325383186, 0.22987931966781616, -0.023019539192318916, 0.05670160800218582, 0.03906968608498573, -0.009256253018975258, 0.004575192928314209, 0.054789163172245026, 0.019259171560406685, -0.09813748300075531, -0.00015211205754894763, 0.031512584537267685, -0.015674326568841934, 0.03540578484535217, 0.010935284197330475, -0.0679895356297493, -0.028932495042681694, 0.024028846994042397, -0.05310330167412758, -0.025005389004945755, 0.02235436625778675, -0.046019140630960464, 0.07040762901306152, 0.0345589742064476, -0.07733152061700821, -0.01352875679731369, -0.04894504323601723, -0.003992456942796707, 0.0373489074409008, -0.028156667947769165, -0.07967016845941544, 0.0057110353372991085, 0.03205903246998787, -0.030483217909932137, 0.015031438320875168, 0.014759558252990246, -0.009081630036234856, 0.01614028960466385, -0.0634353905916214, 0.021307481452822685, -0.006121593527495861, 0.04932289198040962, 0.02275390364229679, 0.026068096980452538]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create index\n",
        "\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex(nodes, embed_model=hf_embeddings)"
      ],
      "metadata": {
        "id": "QiA-I_Y8iI-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUERY"
      ],
      "metadata": {
        "id": "46Tir_aJibnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_querying = Groq(model=\"llama-3.3-70b-versatile\", api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "query_engine = index.as_query_engine(llm=llm_querying)\n",
        "response = query_engine.query(\n",
        "    \"what does this model do?\"\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsvUXOXWiXrd",
        "outputId": "5368f26e-7ae8-4eae-cad8-be563eddf033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model is a Sequential Convolutional Neural Network (CNN) designed for live face detection and spoofing recognition. It uses data augmentation techniques to increase the size of the training data and avoid overfitting, and it is evaluated using specific evaluation metrics such as accuracy, precision, recall, and F1-score. The model is trained on a dataset called CelebA-Spoof, which contains a large number of images of live and spoofed faces, and it is tested using a part of this dataset. The model's primary function is to classify input images as either live or non-live faces, making it a binary classification problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# full schema of response\n",
        "response.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MxXlDIIui-xA",
        "outputId": "23f0fb57-1706-414e-bad7-3c00ec088641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': \"This model is a Sequential Convolutional Neural Network (CNN) designed for live face detection and spoofing recognition. It uses data augmentation techniques to increase the size of the training data and avoid overfitting, and it is evaluated using specific evaluation metrics such as accuracy, precision, recall, and F1-score. The model is trained on a dataset called CelebA-Spoof, which contains a large number of images of live and spoofed faces, and it is tested using a part of this dataset. The model's primary function is to classify input images as either live or non-live faces, making it a binary classification problem.\",\n",
              " 'source_nodes': [NodeWithScore(node=TextNode(id_='b2ae0606-d6f4-44dc-9a81-21da5996f985', embedding=None, metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08', 'document_title': 'Based on the content, I would suggest the following comprehensive title:\\n\\n\"Recent Advances in Face Recognition and Anti-Spoofing: A Review of Deep Learning Techniques, CelebFaces Dataset, and Evaluation Metrics for Biometric Security\"\\n\\nThis title captures the main themes and entities mentioned in the context, including face recognition, anti-spoofing, deep learning, CelebFaces dataset, and evaluation metrics such as ROC curves. It provides a clear and concise summary of the document\\'s content.', 'questions_this_excerpt_can_answer': 'Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\\n\\n1. What is the specific title of the document being referred to, and what are the main themes and entities mentioned in the context?\\n\\nThis question can be answered by referencing the \"document_title\" field, which provides a comprehensive title that captures the main themes and entities mentioned in the context.\\n\\n2. What are the specific references cited in the document, and what are the authors, publication years, and page numbers for each reference?\\n\\nThis question can be answered by referencing the excerpt provided, which lists specific references with authors, publication years, and page numbers.\\n\\n3. What is the file size and creation date of the document, and what is the file path and type?\\n\\nThis question can be answered by referencing the \"file_size\", \"creation_date\", \"file_path\", and \"file_type\" fields, which provide specific information about the document\\'s file properties.\\n\\nHigher-level summaries of surrounding context that may be used to generate better questions include:\\n\\n* The document appears to be a review of recent advances in face recognition and anti-spoofing, with a focus on deep learning techniques and evaluation metrics.\\n* The document cites several references, including academic papers and a book on deep learning with Keras.\\n* The document is likely related to the field of biometric security and may discuss the use of face recognition and anti-spoofing techniques in this context.\\n\\nThese summaries may be used to generate additional questions, such as:\\n\\n* What are the specific deep learning techniques discussed in the document, and how do they relate to face recognition and anti-spoofing?\\n* How do the evaluation metrics discussed in the document, such as ROC curves, relate to the performance of face recognition and anti-spoofing systems?\\n* What are the potential applications of face recognition and anti-spoofing techniques in biometric security, and how do they address specific security challenges?'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'page_label'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f8037f2d-dad5-48fe-810d-a5fb2d4bbacd', node_type='4', metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, hash='e3de51f7adce3b8037bc032945423b90bfe7d37f98e5d539743d4267cfab56a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4a95985-d511-492d-b0d4-623c306de247', node_type='1', metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, hash='2352a666cf96c336b504922873c9053b983bb7a21161559c0b86575dc40103f7')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Luo, X. Wang, and X. Tang, “Large-scale celebfaces attributes\\n(celeba) dataset,” Retrieved August, vol. 15, p. 2018, 2018.\\n[18] A. Gulli and S. Pal, Deep Learning with Keras. Packt Publishing Ltd,\\n2017.\\n[19] J. A. Hanley and B. J. McNeil, “The meaning and use of the area under\\na receiver operating characteristic (roc) curve,” vol. 143, 1982.\\n[20] J. Y . Huy H. Nguyen and I. Echizen, “Use of a capsule network to detect\\nfake images and videos,” 2019.\\n1488\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply.', mimetype='text/plain', start_char_idx=2765, end_char_idx=3370, metadata_seperator='\\n', text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n'), score=0.666540030499282),\n",
              "  NodeWithScore(node=TextNode(id_='277e5640-01ad-4a5c-b728-c9ef0181f701', embedding=None, metadata={'page_label': '4', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08', 'document_title': 'Based on the provided content, I would suggest the following comprehensive title:\\n\\n\"Design and Implementation of a Sequential Convolutional Neural Network for Live Face Detection and Spoofing Recognition: A Study on Data Augmentation, Cross-Validation, and Evaluation Metrics\"\\n\\nThis title captures the main themes and entities mentioned in the content, including the design and implementation of a CNN, live face detection and spoofing recognition, data augmentation, cross-validation, and evaluation metrics.', 'questions_this_excerpt_can_answer': 'Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\\n\\n1. What is the specific architecture of the Sequential Convolutional Neural Network (CNN) used for live face detection and spoofing recognition, including the number of layers, activation functions, and hyperparameters?\\n\\nThis question can be answered by analyzing the excerpt, specifically the sections on \"Design and Implementation of a Sequential Convolutional Neural Network\" and \"Compiling the CNN\". The answer would provide a detailed description of the CNN architecture, including the number of layers, activation functions, and hyperparameters used.\\n\\n2. What are the specific data augmentation techniques used to increase the size of the training data and avoid overfitting in the proposed model, and how do these techniques improve the performance of the model?\\n\\nThis question can be answered by analyzing the excerpt, specifically the section on \"Data Augmentation\". The answer would provide a detailed description of the data augmentation techniques used, such as rescale, shear, zoom, and horizontal flip, and how these techniques improve the performance of the model.\\n\\n3. What are the specific evaluation metrics used to assess the performance of the proposed model, and how do these metrics compare to other existing models in the field of live face detection and spoofing recognition?\\n\\nThis question can be answered by analyzing the excerpt, specifically the section on \"Compiling the CNN\" and the equation for calculating accuracy. The answer would provide a detailed description of the evaluation metrics used, such as accuracy, precision, recall, and F1-score, and how these metrics compare to other existing models in the field.\\n\\nHigher-level summaries of surrounding context that may be useful for generating better questions include:\\n\\n* The context is related to the field of computer vision and machine learning, specifically in the area of live face detection and spoofing recognition.\\n* The proposed model is a Sequential Convolutional Neural Network (CNN) that uses data augmentation techniques to increase the size of the training data and avoid overfitting.\\n* The model is evaluated using specific evaluation metrics, such as accuracy, precision, recall, and F1-score.\\n\\nThese summaries can be used to generate more specific and targeted questions that this context can answer.'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'page_label'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9bc18b38-fa59-4742-bd0d-2d9eb9ba48e2', node_type='4', metadata={'page_label': '4', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, hash='2a0800a24cdb7fcd12e1b2cebbdf5a1d5ad6f190de03e0e3594280541f10401f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec4dff58-7338-499a-8e85-63f9e474f6a8', node_type='1', metadata={}, hash='7b467f756ece6f306b1577da69b648d155a245619ee5c9537fa6ecd845602de0')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Fig. 6: Zoom augmentation results\\nappear as dots in the manipulated images. That makes\\nimages becomes clearer.\\nC. classiﬁcation stage\\n• ﬂatten layer: the function of this layer is to structure the\\nfeature maps into a single vector suitable to be processed\\nby the next neural network layer.\\n• dense and relu activation function: dense function in keras\\nbuilds a neural network with a speciﬁc number of hidden\\nnodes and a relu activation function. It takes the ﬂattened\\nvector to be as an input to the neural network.\\n• dropout: its function is to prevent overﬁtting.\\n• dense and sigmoid activation function: it constitutes the\\noutput layer with sigmoid function since it is a binary\\nclassiﬁcation problem (live or non\\nlive face)\\nD. compiling the CNN\\nto compile the constructed CNN, the function compile is\\nused with three parameters: the optimizer is rmsprop, the\\nloss function is binary\\ncrossentropy and the performance\\nmetric is accuracy. The optimizer rmsprop is an adaptive\\nlearning rate method proposed in [15]. The calculation of\\nbinary\\ncrossentropy loss function is shown in equation 1\\nLoss = − 1\\noutput\\noutput∑\\nsize\\nyi ·log ˆyi +(1 − yi)·log(1 − ˆyi) (1)\\nwhere ˆyi is the i -th scalar value in the model output,yi is\\nthe corresponding target value, and output size is the number\\nof scalar values in the model output. The accuracy is calculated\\nas shown in equation 2\\nAccuracy = (TP+TN)/(TP+TN+FP+FN) (2)\\nIV . E\\nXPERIMENTAL RESULTS\\nThis section introduces the outcome of the experiments\\nperformed using a sequential CNN as described in the previous\\nsection.\\nA. Setup of the Experiment\\nThe experiments were done on a machine equipped with\\nan Intel Core i7-4790 @ 3.6GHZ, 16GB of memory, and\\nan NVIDIA GTX1060 GPU card. The machine runs on\\nWindows10. The experiments were done using python pro-\\ngramming language and keras framework. The experiment\\nwere done using a dataset called CelebA dataset. 2000 pictures\\nwere used for training and 200 pictures were used for testing\\ndivided equally between live and spoof to be balanced.\\nB. Dataset description\\nA novel anti-spooﬁng dataset CelebA-Spoof has been col-\\nlected to recognize live and non-live faces [16]. The main\\nadvantages of CelebA-Spoof are the following:\\n• Quantity: CelebA-Spoof contains 625,537 pictures of\\n10,177 subjects, which is larger than any existing dataset\\nrelated to this ﬁeld.\\n• Diversity: The spoofed images are taken from 8 scenes\\n(2 environments * 4 illumination conditions) with more\\nthan 10 sensors.\\n• Annotation Richness: CelebA-Spoof contains 10 spoof\\ntype annotations, as well as the 40 attribute annotations\\ninherited from the original CelebA dataset [17]\\n• Date: The dataset was made and published in 2020 and\\nit is the newest dataset related to this ﬁeld.\\nThe proposed model is Sequential CNN. It has been tested\\nand cross validated using a part of CelebA-Spoof dataset.\\nC. Training and testing\\nThe data set has been read using ImageDataGenerator [18]\\nwhich is Keras function that will be used in ﬁt generator\\nfunction of the sequential model in Keras that is used for\\ntraining images. The ImageDataGenerator generates classes\\nautomatically from the number of folders existing in the path\\ngiven to it and ﬁt generator [18] function knows how to work\\nwith the information given. This is used in case of testing.\\nImageDataGenerator is also used in augmentation [13]\\npart to increase the size of the training data and to avoid\\noverﬁtting. Augmentation methods used are rescale to make\\nnormalization, Shear to make the image distorted along an\\naxis, zoom to put in consideration the distance from the camera\\nto the face, and horizontal ﬂip.\\nIn cross-validation, we could not use ImageDataGenerator\\nwith K-Fold methods to dividing the dataset into train and\\ntest randomly each time with a different output of images each\\ntime. So, We had to convert the object of ImageDataGenerator\\nthat contains the dataset into two arrays.', mimetype='text/plain', start_char_idx=0, end_char_idx=3905, metadata_seperator='\\n', text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n'), score=0.6471042996429625)],\n",
              " 'metadata': {'b2ae0606-d6f4-44dc-9a81-21da5996f985': {'page_label': '6',\n",
              "   'file_name': 'mohamed2021.pdf',\n",
              "   'file_path': '/content/data/mohamed2021.pdf',\n",
              "   'file_type': 'application/pdf',\n",
              "   'file_size': 528244,\n",
              "   'creation_date': '2025-06-08',\n",
              "   'last_modified_date': '2025-06-08',\n",
              "   'document_title': 'Based on the content, I would suggest the following comprehensive title:\\n\\n\"Recent Advances in Face Recognition and Anti-Spoofing: A Review of Deep Learning Techniques, CelebFaces Dataset, and Evaluation Metrics for Biometric Security\"\\n\\nThis title captures the main themes and entities mentioned in the context, including face recognition, anti-spoofing, deep learning, CelebFaces dataset, and evaluation metrics such as ROC curves. It provides a clear and concise summary of the document\\'s content.',\n",
              "   'questions_this_excerpt_can_answer': 'Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\\n\\n1. What is the specific title of the document being referred to, and what are the main themes and entities mentioned in the context?\\n\\nThis question can be answered by referencing the \"document_title\" field, which provides a comprehensive title that captures the main themes and entities mentioned in the context.\\n\\n2. What are the specific references cited in the document, and what are the authors, publication years, and page numbers for each reference?\\n\\nThis question can be answered by referencing the excerpt provided, which lists specific references with authors, publication years, and page numbers.\\n\\n3. What is the file size and creation date of the document, and what is the file path and type?\\n\\nThis question can be answered by referencing the \"file_size\", \"creation_date\", \"file_path\", and \"file_type\" fields, which provide specific information about the document\\'s file properties.\\n\\nHigher-level summaries of surrounding context that may be used to generate better questions include:\\n\\n* The document appears to be a review of recent advances in face recognition and anti-spoofing, with a focus on deep learning techniques and evaluation metrics.\\n* The document cites several references, including academic papers and a book on deep learning with Keras.\\n* The document is likely related to the field of biometric security and may discuss the use of face recognition and anti-spoofing techniques in this context.\\n\\nThese summaries may be used to generate additional questions, such as:\\n\\n* What are the specific deep learning techniques discussed in the document, and how do they relate to face recognition and anti-spoofing?\\n* How do the evaluation metrics discussed in the document, such as ROC curves, relate to the performance of face recognition and anti-spoofing systems?\\n* What are the potential applications of face recognition and anti-spoofing techniques in biometric security, and how do they address specific security challenges?'},\n",
              "  '277e5640-01ad-4a5c-b728-c9ef0181f701': {'page_label': '4',\n",
              "   'file_name': 'mohamed2021.pdf',\n",
              "   'file_path': '/content/data/mohamed2021.pdf',\n",
              "   'file_type': 'application/pdf',\n",
              "   'file_size': 528244,\n",
              "   'creation_date': '2025-06-08',\n",
              "   'last_modified_date': '2025-06-08',\n",
              "   'document_title': 'Based on the provided content, I would suggest the following comprehensive title:\\n\\n\"Design and Implementation of a Sequential Convolutional Neural Network for Live Face Detection and Spoofing Recognition: A Study on Data Augmentation, Cross-Validation, and Evaluation Metrics\"\\n\\nThis title captures the main themes and entities mentioned in the content, including the design and implementation of a CNN, live face detection and spoofing recognition, data augmentation, cross-validation, and evaluation metrics.',\n",
              "   'questions_this_excerpt_can_answer': 'Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\\n\\n1. What is the specific architecture of the Sequential Convolutional Neural Network (CNN) used for live face detection and spoofing recognition, including the number of layers, activation functions, and hyperparameters?\\n\\nThis question can be answered by analyzing the excerpt, specifically the sections on \"Design and Implementation of a Sequential Convolutional Neural Network\" and \"Compiling the CNN\". The answer would provide a detailed description of the CNN architecture, including the number of layers, activation functions, and hyperparameters used.\\n\\n2. What are the specific data augmentation techniques used to increase the size of the training data and avoid overfitting in the proposed model, and how do these techniques improve the performance of the model?\\n\\nThis question can be answered by analyzing the excerpt, specifically the section on \"Data Augmentation\". The answer would provide a detailed description of the data augmentation techniques used, such as rescale, shear, zoom, and horizontal flip, and how these techniques improve the performance of the model.\\n\\n3. What are the specific evaluation metrics used to assess the performance of the proposed model, and how do these metrics compare to other existing models in the field of live face detection and spoofing recognition?\\n\\nThis question can be answered by analyzing the excerpt, specifically the section on \"Compiling the CNN\" and the equation for calculating accuracy. The answer would provide a detailed description of the evaluation metrics used, such as accuracy, precision, recall, and F1-score, and how these metrics compare to other existing models in the field.\\n\\nHigher-level summaries of surrounding context that may be useful for generating better questions include:\\n\\n* The context is related to the field of computer vision and machine learning, specifically in the area of live face detection and spoofing recognition.\\n* The proposed model is a Sequential Convolutional Neural Network (CNN) that uses data augmentation techniques to increase the size of the training data and avoid overfitting.\\n* The model is evaluated using specific evaluation metrics, such as accuracy, precision, recall, and F1-score.\\n\\nThese summaries can be used to generate more specific and targeted questions that this context can answer.'}}}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(response.source_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGL96RmZjQqP",
        "outputId": "b8e43c14-5136-4887-c45a-a2712b7d8fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NodeWithScore(node=TextNode(id_='b2ae0606-d6f4-44dc-9a81-21da5996f985', embedding=None, metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08', 'document_title': 'Based on the content, I would suggest the following comprehensive title:\\n\\n\"Recent Advances in Face Recognition and Anti-Spoofing: A Review of Deep Learning Techniques, CelebFaces Dataset, and Evaluation Metrics for Biometric Security\"\\n\\nThis title captures the main themes and entities mentioned in the context, including face recognition, anti-spoofing, deep learning, CelebFaces dataset, and evaluation metrics such as ROC curves. It provides a clear and concise summary of the document\\'s content.', 'questions_this_excerpt_can_answer': 'Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\\n\\n1. What is the specific title of the document being referred to, and what are the main themes and entities mentioned in the context?\\n\\nThis question can be answered by referencing the \"document_title\" field, which provides a comprehensive title that captures the main themes and entities mentioned in the context.\\n\\n2. What are the specific references cited in the document, and what are the authors, publication years, and page numbers for each reference?\\n\\nThis question can be answered by referencing the excerpt provided, which lists specific references with authors, publication years, and page numbers.\\n\\n3. What is the file size and creation date of the document, and what is the file path and type?\\n\\nThis question can be answered by referencing the \"file_size\", \"creation_date\", \"file_path\", and \"file_type\" fields, which provide specific information about the document\\'s file properties.\\n\\nHigher-level summaries of surrounding context that may be used to generate better questions include:\\n\\n* The document appears to be a review of recent advances in face recognition and anti-spoofing, with a focus on deep learning techniques and evaluation metrics.\\n* The document cites several references, including academic papers and a book on deep learning with Keras.\\n* The document is likely related to the field of biometric security and may discuss the use of face recognition and anti-spoofing techniques in this context.\\n\\nThese summaries may be used to generate additional questions, such as:\\n\\n* What are the specific deep learning techniques discussed in the document, and how do they relate to face recognition and anti-spoofing?\\n* How do the evaluation metrics discussed in the document, such as ROC curves, relate to the performance of face recognition and anti-spoofing systems?\\n* What are the potential applications of face recognition and anti-spoofing techniques in biometric security, and how do they address specific security challenges?'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'page_label'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f8037f2d-dad5-48fe-810d-a5fb2d4bbacd', node_type='4', metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, hash='e3de51f7adce3b8037bc032945423b90bfe7d37f98e5d539743d4267cfab56a5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4a95985-d511-492d-b0d4-623c306de247', node_type='1', metadata={'page_label': '6', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, hash='2352a666cf96c336b504922873c9053b983bb7a21161559c0b86575dc40103f7')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Luo, X. Wang, and X. Tang, “Large-scale celebfaces attributes\\n(celeba) dataset,” Retrieved August, vol. 15, p. 2018, 2018.\\n[18] A. Gulli and S. Pal, Deep Learning with Keras. Packt Publishing Ltd,\\n2017.\\n[19] J. A. Hanley and B. J. McNeil, “The meaning and use of the area under\\na receiver operating characteristic (roc) curve,” vol. 143, 1982.\\n[20] J. Y . Huy H. Nguyen and I. Echizen, “Use of a capsule network to detect\\nfake images and videos,” 2019.\\n1488\\nAuthorized licensed use limited to: American University of Beirut. Downloaded on May 28,2021 at 15:20:42 UTC from IEEE Xplore.  Restrictions apply.', mimetype='text/plain', start_char_idx=2765, end_char_idx=3370, metadata_seperator='\\n', text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n'), score=0.666540030499282),\n",
            " NodeWithScore(node=TextNode(id_='277e5640-01ad-4a5c-b728-c9ef0181f701', embedding=None, metadata={'page_label': '4', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08', 'document_title': 'Based on the provided content, I would suggest the following comprehensive title:\\n\\n\"Design and Implementation of a Sequential Convolutional Neural Network for Live Face Detection and Spoofing Recognition: A Study on Data Augmentation, Cross-Validation, and Evaluation Metrics\"\\n\\nThis title captures the main themes and entities mentioned in the content, including the design and implementation of a CNN, live face detection and spoofing recognition, data augmentation, cross-validation, and evaluation metrics.', 'questions_this_excerpt_can_answer': 'Based on the provided context, here are three questions that this context can provide specific answers to, which are unlikely to be found elsewhere:\\n\\n1. What is the specific architecture of the Sequential Convolutional Neural Network (CNN) used for live face detection and spoofing recognition, including the number of layers, activation functions, and hyperparameters?\\n\\nThis question can be answered by analyzing the excerpt, specifically the sections on \"Design and Implementation of a Sequential Convolutional Neural Network\" and \"Compiling the CNN\". The answer would provide a detailed description of the CNN architecture, including the number of layers, activation functions, and hyperparameters used.\\n\\n2. What are the specific data augmentation techniques used to increase the size of the training data and avoid overfitting in the proposed model, and how do these techniques improve the performance of the model?\\n\\nThis question can be answered by analyzing the excerpt, specifically the section on \"Data Augmentation\". The answer would provide a detailed description of the data augmentation techniques used, such as rescale, shear, zoom, and horizontal flip, and how these techniques improve the performance of the model.\\n\\n3. What are the specific evaluation metrics used to assess the performance of the proposed model, and how do these metrics compare to other existing models in the field of live face detection and spoofing recognition?\\n\\nThis question can be answered by analyzing the excerpt, specifically the section on \"Compiling the CNN\" and the equation for calculating accuracy. The answer would provide a detailed description of the evaluation metrics used, such as accuracy, precision, recall, and F1-score, and how these metrics compare to other existing models in the field.\\n\\nHigher-level summaries of surrounding context that may be useful for generating better questions include:\\n\\n* The context is related to the field of computer vision and machine learning, specifically in the area of live face detection and spoofing recognition.\\n* The proposed model is a Sequential Convolutional Neural Network (CNN) that uses data augmentation techniques to increase the size of the training data and avoid overfitting.\\n* The model is evaluated using specific evaluation metrics, such as accuracy, precision, recall, and F1-score.\\n\\nThese summaries can be used to generate more specific and targeted questions that this context can answer.'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date', 'page_label'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9bc18b38-fa59-4742-bd0d-2d9eb9ba48e2', node_type='4', metadata={'page_label': '4', 'file_name': 'mohamed2021.pdf', 'file_path': '/content/data/mohamed2021.pdf', 'file_type': 'application/pdf', 'file_size': 528244, 'creation_date': '2025-06-08', 'last_modified_date': '2025-06-08'}, hash='2a0800a24cdb7fcd12e1b2cebbdf5a1d5ad6f190de03e0e3594280541f10401f'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='ec4dff58-7338-499a-8e85-63f9e474f6a8', node_type='1', metadata={}, hash='7b467f756ece6f306b1577da69b648d155a245619ee5c9537fa6ecd845602de0')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Fig. 6: Zoom augmentation results\\nappear as dots in the manipulated images. That makes\\nimages becomes clearer.\\nC. classiﬁcation stage\\n• ﬂatten layer: the function of this layer is to structure the\\nfeature maps into a single vector suitable to be processed\\nby the next neural network layer.\\n• dense and relu activation function: dense function in keras\\nbuilds a neural network with a speciﬁc number of hidden\\nnodes and a relu activation function. It takes the ﬂattened\\nvector to be as an input to the neural network.\\n• dropout: its function is to prevent overﬁtting.\\n• dense and sigmoid activation function: it constitutes the\\noutput layer with sigmoid function since it is a binary\\nclassiﬁcation problem (live or non\\nlive face)\\nD. compiling the CNN\\nto compile the constructed CNN, the function compile is\\nused with three parameters: the optimizer is rmsprop, the\\nloss function is binary\\ncrossentropy and the performance\\nmetric is accuracy. The optimizer rmsprop is an adaptive\\nlearning rate method proposed in [15]. The calculation of\\nbinary\\ncrossentropy loss function is shown in equation 1\\nLoss = − 1\\noutput\\noutput∑\\nsize\\nyi ·log ˆyi +(1 − yi)·log(1 − ˆyi) (1)\\nwhere ˆyi is the i -th scalar value in the model output,yi is\\nthe corresponding target value, and output size is the number\\nof scalar values in the model output. The accuracy is calculated\\nas shown in equation 2\\nAccuracy = (TP+TN)/(TP+TN+FP+FN) (2)\\nIV . E\\nXPERIMENTAL RESULTS\\nThis section introduces the outcome of the experiments\\nperformed using a sequential CNN as described in the previous\\nsection.\\nA. Setup of the Experiment\\nThe experiments were done on a machine equipped with\\nan Intel Core i7-4790 @ 3.6GHZ, 16GB of memory, and\\nan NVIDIA GTX1060 GPU card. The machine runs on\\nWindows10. The experiments were done using python pro-\\ngramming language and keras framework. The experiment\\nwere done using a dataset called CelebA dataset. 2000 pictures\\nwere used for training and 200 pictures were used for testing\\ndivided equally between live and spoof to be balanced.\\nB. Dataset description\\nA novel anti-spooﬁng dataset CelebA-Spoof has been col-\\nlected to recognize live and non-live faces [16]. The main\\nadvantages of CelebA-Spoof are the following:\\n• Quantity: CelebA-Spoof contains 625,537 pictures of\\n10,177 subjects, which is larger than any existing dataset\\nrelated to this ﬁeld.\\n• Diversity: The spoofed images are taken from 8 scenes\\n(2 environments * 4 illumination conditions) with more\\nthan 10 sensors.\\n• Annotation Richness: CelebA-Spoof contains 10 spoof\\ntype annotations, as well as the 40 attribute annotations\\ninherited from the original CelebA dataset [17]\\n• Date: The dataset was made and published in 2020 and\\nit is the newest dataset related to this ﬁeld.\\nThe proposed model is Sequential CNN. It has been tested\\nand cross validated using a part of CelebA-Spoof dataset.\\nC. Training and testing\\nThe data set has been read using ImageDataGenerator [18]\\nwhich is Keras function that will be used in ﬁt generator\\nfunction of the sequential model in Keras that is used for\\ntraining images. The ImageDataGenerator generates classes\\nautomatically from the number of folders existing in the path\\ngiven to it and ﬁt generator [18] function knows how to work\\nwith the information given. This is used in case of testing.\\nImageDataGenerator is also used in augmentation [13]\\npart to increase the size of the training data and to avoid\\noverﬁtting. Augmentation methods used are rescale to make\\nnormalization, Shear to make the image distorted along an\\naxis, zoom to put in consideration the distance from the camera\\nto the face, and horizontal ﬂip.\\nIn cross-validation, we could not use ImageDataGenerator\\nwith K-Fold methods to dividing the dataset into train and\\ntest randomly each time with a different output of images each\\ntime. So, We had to convert the object of ImageDataGenerator\\nthat contains the dataset into two arrays.', mimetype='text/plain', start_char_idx=0, end_char_idx=3905, metadata_seperator='\\n', text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n'), score=0.6471042996429625)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STORE"
      ],
      "metadata": {
        "id": "JCA-fw38jusn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.storage_context.persist(persist_dir=\"./vectors\")"
      ],
      "metadata": {
        "id": "3PSTfsc1jpho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "# rebuild storage context\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./vectors\")\n",
        "\n",
        "# load index\n",
        "index_from_storage = load_index_from_storage(storage_context, embed_model=hf_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ZYYW5bkdFu",
        "outputId": "46e5544b-31bf-45fe-d8eb-5c4f18e1e126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading llama_index.core.storage.kvstore.simple_kvstore from ./vectors/docstore.json.\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from ./vectors/index_store.json.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = index_from_storage.as_query_engine(llm=llm_querying)"
      ],
      "metadata": {
        "id": "MAEOU49ukruJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa.query(\"what does this model do?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSvVqPMnkuzq",
        "outputId": "d81596f5-dbb5-457e-873a-ba0b2bf304b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model is a Sequential Convolutional Neural Network (CNN) designed for live face detection and spoofing recognition. It uses data augmentation techniques to increase the size of the training data and avoid overfitting, and it is evaluated using specific evaluation metrics such as accuracy, precision, recall, and F1-score. The model is trained on a dataset called CelebA-Spoof, which contains a large number of pictures of live and spoofed faces, and it is tested using a part of this dataset. The model's primary function is to classify faces as either live or non-live, making it a binary classification problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "USING VECTOR STORES"
      ],
      "metadata": {
        "id": "jg8bzBbrkys0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -Uq chromadb\n",
        "%pip install -Uq llama-index-vector-stores-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB5518WBkxSJ",
        "outputId": "1c2a060d-5bb9-431d-b4bd-9397f104221b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "# initialize client, setting path to save data\n",
        "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "\n",
        "# create collection\n",
        "chroma_collection = db.get_or_create_collection(\"fldetectionGPT\") # actual collection returned from the chroma client\n",
        "\n",
        "# assign chroma as the vector_store to the context\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)  #native chroma clinet comes into contact with the 3rd party integartion of llama index\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# create your index\n",
        "index = VectorStoreIndex(\n",
        "    nodes, storage_context=storage_context, embed_model=hf_embeddings\n",
        ")\n",
        "\n",
        "# You can also load from documents and apply transformations in place\n",
        "# index = VectorStoreIndex.from_documents(\n",
        "#     documents, storage_context=storage_context, transformations=[]\n",
        "# )\n",
        "\n",
        "# Or you can initialize your index from your vector store and then add the nodes\n",
        "# index = VectorStoreIndex.from_vector_store(\n",
        "#     vector_store=vector_store, embed_model=hf_embeddings\n",
        "# )\n",
        "# index.insert_nodes(nodes)\n",
        "\n",
        "\n",
        "# create a query engine and query\n",
        "query_engine = index.as_query_engine(llm=llm_querying)"
      ],
      "metadata": {
        "id": "uQD_ZuClk6oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is this model good at?\")\n",
        "print(response)\n",
        "\n",
        "# the ans r being retrieved from chroma_db vector store; its very persistent and i can run it directly also"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIJrO687miI_",
        "outputId": "c2269ac4-1614-4b8b-926b-3be52f59cd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This model is good at live face detection and spoofing recognition. It uses a Sequential Convolutional Neural Network (CNN) to classify faces as either live or non-live, and it has been tested and cross-validated using a dataset called CelebA-Spoof. The model is also capable of data augmentation, which helps to increase the size of the training data and avoid overfitting. Additionally, the model is evaluated using metrics such as accuracy, precision, recall, and F1-score, which suggests that it is designed to provide accurate and reliable results in the field of face recognition and anti-spoofing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hTEiz0i1m1-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}