{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVhknNCLNSfc"
      },
      "outputs": [],
      "source": [
        "    ! pip install \"unstructured[all-docs]\" pillow pydantic lxml pillow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n"
      ],
      "metadata": {
        "id": "JSdHyNAeNc4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "8DAb4AsiNhci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libleptonica-dev tesseract-ocr libtesseract-dev python3-pil tesseract-ocr-eng tesseract-ocr-script-latn"
      ],
      "metadata": {
        "id": "79m_aX8UNi2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured-pytesseract\n",
        "!pip install tesseract-ocr"
      ],
      "metadata": {
        "id": "RULUzM4SNkyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.partition.pdf import partition_pdf"
      ],
      "metadata": {
        "id": "i4UC_HPQNmY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements=partition_pdf(\n",
        "    filename=\"/content/\",                  # mandatory\n",
        "    strategy=\"hi_res\",                                 # mandatory to use ``hi_res`` strategy\n",
        "    extract_images_in_pdf=True,                       # mandatory to set as ``True``\n",
        "    extract_image_block_types=[\"Image\", \"Table\"],          # optional\n",
        "    extract_image_block_to_payload=False,                  # optional\n",
        "    extract_image_block_output_dir=\"extracted_data\",  # optional - only works when ``extract_image_block_to_payload=False``\n",
        "    )"
      ],
      "metadata": {
        "id": "WiY2qvXWNpQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements"
      ],
      "metadata": {
        "id": "vNZ6nwSxNtQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Header=[]\n",
        "Footer=[]\n",
        "Title=[]\n",
        "NarrativeText=[]\n",
        "Text=[]\n",
        "ListItem=[]\n",
        "for element in raw_pdf_elements:\n",
        "  if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
        "            Header.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
        "            Footer.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
        "            Title.append(str(element))\n",
        "  elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "            NarrativeText.append(str(element))\n",
        "  elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
        "            Text.append(str(element))\n",
        "  elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
        "            ListItem.append(str(element))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U3Q1u0raNug6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=[]\n",
        "for element in raw_pdf_elements:\n",
        "  if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "            img.append(str(element))"
      ],
      "metadata": {
        "id": "7GGDic2KNwDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tab=[]\n",
        "for element in raw_pdf_elements:\n",
        "  if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "            tab.append(str(element))"
      ],
      "metadata": {
        "id": "K8qOzde1NxNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tab"
      ],
      "metadata": {
        "id": "qPsCJWp0NzJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "2Krhwr_qN0Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements2=partition_pdf(\n",
        "    filename=\"/content/\",                  # mandatory\n",
        "    strategy=\"hi_res\",                                 # mandatory to use ``hi_res`` strategy\n",
        "    extract_images_in_pdf=True,                       # mandatory to set as ``True``\n",
        "    extract_image_block_types=[\"Image\",\"Table\"],          # optional\n",
        "    extract_image_block_to_payload=False,                  # optional\n",
        "    extract_image_block_output_dir=\"extracted_data2\",  # optional - only works when ``extract_image_block_to_payload=False``\n",
        "    )"
      ],
      "metadata": {
        "id": "Csve3BBZN245"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_pdf_elements2"
      ],
      "metadata": {
        "id": "BGcbff4sN5Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Table=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
        "            Table.append(str(element))"
      ],
      "metadata": {
        "id": "6iNCkZP2N6m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Table"
      ],
      "metadata": {
        "id": "PHKynkFpN7zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
        "            Text.append(str(element))"
      ],
      "metadata": {
        "id": "f3CxJ0GAN8yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text"
      ],
      "metadata": {
        "id": "pVgKNDJgN9zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image=[]\n",
        "for element in raw_pdf_elements2:\n",
        "  if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
        "            Image.append(str(element))"
      ],
      "metadata": {
        "id": "vyX1tD88OAk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image"
      ],
      "metadata": {
        "id": "omBoTID5OB-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_core\n",
        "!pip install langchain_openai\n",
        "!pip install langchain\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "FL6fzzbLODPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oxbhDedGOGZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "j54mKIkeOGIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "prompt_text = \"\"\"You are an assistant tasked with summarizing tables for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw table elements. \\\n",
        "    Give a concise summary of the table that is well optimized for retrieval. Table:{element} \"\"\""
      ],
      "metadata": {
        "id": "c-0jrd_TOH3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(prompt_text)"
      ],
      "metadata": {
        "id": "KIDqCwhtOJiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "OPENAI_API_TOKEN=userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN"
      ],
      "metadata": {
        "id": "iF4Zoeo-OLRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text summary chain\n",
        "model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "J3F6LSN_OM67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_summaries = []"
      ],
      "metadata": {
        "id": "AKOqONeGOOIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_summaries = summarize_chain.batch(Table, {\"max_concurrency\": 5})"
      ],
      "metadata": {
        "id": "nW-P-sgDOQER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_summaries"
      ],
      "metadata": {
        "id": "WMiIPL1JORId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "prompt_text = \"\"\"You are an assistant tasked with summarizing text for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw text elements. \\\n",
        "    Give a concise summary of the table or text that is well optimized for retrieval.text: {element} \"\"\"\n"
      ],
      "metadata": {
        "id": "6he7Mtw0OSzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(prompt_text)"
      ],
      "metadata": {
        "id": "OJpfLSdPOUKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text summary chain\n",
        "model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "zgObtFgZOVK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty summaries\n",
        "\n",
        "text_summaries = []\n"
      ],
      "metadata": {
        "id": "6s-U_4SkOWRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summaries = summarize_chain.batch(Text, {\"max_concurrency\": 5})"
      ],
      "metadata": {
        "id": "jYSMJfCkOXcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summaries"
      ],
      "metadata": {
        "id": "REQhyxocOYa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "Ws3iT7Q_OaY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "    \"\"\"Getting the base64 string\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "Bs0K22oLObjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_summarize(img_base64, prompt):\n",
        "    \"\"\"Make image summary\"\"\"\n",
        "    chat = ChatOpenAI(model=\"gpt-4-turbo-2024-04-09\", max_tokens=1024)\n",
        "\n",
        "    msg = chat.invoke(\n",
        "        [\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"},\n",
        "                    },\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return msg.content"
      ],
      "metadata": {
        "id": "xhTS3_XaOcl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_img_summaries(path):\n",
        "    \"\"\"\n",
        "    Generate summaries and base64 encoded strings for images\n",
        "    path: Path to list of .jpg files extracted by Unstructured\n",
        "    \"\"\"\n",
        "\n",
        "    # Store base64 encoded images\n",
        "    img_base64_list = []\n",
        "\n",
        "    # Store image summaries\n",
        "    image_summaries = []\n",
        "\n",
        "    # Prompt\n",
        "    prompt = \"\"\"You are an assistant tasked with summarizing images for retrieval. \\\n",
        "    These summaries will be embedded and used to retrieve the raw image. \\\n",
        "    Give a concise summary of the image that is well optimized for retrieval.\"\"\"\n",
        "\n",
        "    # Apply to images\n",
        "    for img_file in sorted(os.listdir(path)):\n",
        "        if img_file.endswith(\".jpg\"):\n",
        "            img_path = os.path.join(path, img_file)\n",
        "            base64_image = encode_image(img_path)\n",
        "            img_base64_list.append(base64_image)\n",
        "            image_summaries.append(image_summarize(base64_image, prompt))\n",
        "\n",
        "\n",
        "    return img_base64_list, image_summaries"
      ],
      "metadata": {
        "id": "t0TwhUFxOeGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpath=\"/content/extracted_data2/\""
      ],
      "metadata": {
        "id": "yBPoBqNXOhQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_base64_list, image_summaries = generate_img_summaries(fpath)"
      ],
      "metadata": {
        "id": "TLoxhBK2Ojcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_summaries"
      ],
      "metadata": {
        "id": "InZwFsFNOkgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_base64_list"
      ],
      "metadata": {
        "id": "N5DwlDAxOlzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "x5Kk3KBAOnuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "YjpKblJSOpbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multi_vector_retriever(vectorstore, text_summaries, texts, table_summaries, tables, image_summaries, images):\n",
        "    \"\"\"\n",
        "    Create retriever that indexes summaries, but returns raw images or texts\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize the storage layer\n",
        "    store = InMemoryStore()\n",
        "    id_key = \"doc_id\"\n",
        "\n",
        "    # Create the multi-vector retriever\n",
        "    retriever = MultiVectorRetriever(\n",
        "        vectorstore=vectorstore,\n",
        "        docstore=store,\n",
        "        id_key=id_key,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Helper function to add documents to the vectorstore and docstore\n",
        "    def add_documents(retriever, doc_summaries, doc_contents):\n",
        "\n",
        "      doc_ids = [str(uuid.uuid4()) for _ in doc_contents]\n",
        "\n",
        "      summary_docs = [\n",
        "              Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "              for i, s in enumerate(doc_summaries)\n",
        "          ]\n",
        "\n",
        "      retriever.vectorstore.add_documents(summary_docs)\n",
        "      retriever.docstore.mset(list(zip(doc_ids, doc_contents)))\n",
        "\n",
        "      # Add texts, tables, and images\n",
        "      # Check that text_summaries is not empty before adding\n",
        "      if text_summaries:\n",
        "          add_documents(retriever, text_summaries, texts)\n",
        "      # Check that table_summaries is not empty before adding\n",
        "      if table_summaries:\n",
        "          add_documents(retriever, table_summaries, tab)\n",
        "      # Check that image_summaries is not empty before adding\n",
        "      if image_summaries:\n",
        "          add_documents(retriever, image_summaries, img)\n",
        "\n",
        "    return retriever\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    collection_name=\"mm_rag\", embedding_function=OpenAIEmbeddings()\n",
        ")\n",
        "\n",
        "# Create retriever\n",
        "retriever_multi_vector_img = create_multi_vector_retriever(\n",
        "    vectorstore,\n",
        "    text_summaries,\n",
        "    Text,\n",
        "    table_summaries,\n",
        "    Table,\n",
        "    image_summaries,\n",
        "    img_base64_list,\n",
        ")"
      ],
      "metadata": {
        "id": "rGESK5O3Oqng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_multi_vector_img"
      ],
      "metadata": {
        "id": "EQxppe6AOsbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "ghjIWbAZOtib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_img_base64(img_base64):\n",
        "    \"\"\"Disply base64 encoded string as image\"\"\"\n",
        "    # Create an HTML img tag with the base64 string as the source\n",
        "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
        "    # Display the image by rendering the HTML\n",
        "    display(HTML(image_html))\n"
      ],
      "metadata": {
        "id": "ri36onmUOurX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt_img_base64(img_base64_list[1])"
      ],
      "metadata": {
        "id": "i6cMlpNoOvuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_summaries[1]"
      ],
      "metadata": {
        "id": "M6h37pf8OxBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def looks_like_base64(sb):\n",
        "    \"\"\"Check if the string looks like base64\"\"\"\n",
        "    return re.match(\"^[A-Za-z0-9+/]+[=]{0,2}$\", sb) is not None\n"
      ],
      "metadata": {
        "id": "EKLcZzg4Ox51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_data(b64data):\n",
        "    \"\"\"\n",
        "    Check if the base64 data is an image by looking at the start of the data\n",
        "    \"\"\"\n",
        "    image_signatures = {\n",
        "        b\"\\xFF\\xD8\\xFF\": \"jpg\",\n",
        "        b\"\\x89\\x50\\x4E\\x47\\x0D\\x0A\\x1A\\x0A\": \"png\",\n",
        "        b\"\\x47\\x49\\x46\\x38\": \"gif\",\n",
        "        b\"\\x52\\x49\\x46\\x46\": \"webp\",\n",
        "    }\n",
        "    try:\n",
        "        header = base64.b64decode(b64data)[:8]  # Decode and get the first 8 bytes\n",
        "        for sig, format in image_signatures.items():\n",
        "            if header.startswith(sig):\n",
        "                return True\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False"
      ],
      "metadata": {
        "id": "mJD9DbuwOzBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_image_text_types(docs):\n",
        "    \"\"\"\n",
        "    Split base64-encoded images and texts\n",
        "    \"\"\"\n",
        "    b64_images = []\n",
        "    texts = []\n",
        "\n",
        "    for doc in docs:\n",
        "        # Check if the document is of type Document and extract page_content if so\n",
        "        if isinstance(doc, Document):\n",
        "            doc = doc.page_content\n",
        "        if looks_like_base64(doc) and is_image_data(doc):\n",
        "            doc = resize_base64_image(doc, size=(1300, 600))\n",
        "            b64_images.append(doc)\n",
        "        else:\n",
        "            texts.append(doc)\n",
        "\n",
        "    return {\"images\": b64_images, \"texts\": texts}"
      ],
      "metadata": {
        "id": "DSMNn7UkO8Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def img_prompt_func(data_dict):\n",
        "    \"\"\"\n",
        "    Join the context into a single string\n",
        "    \"\"\"\n",
        "    #print(data_dict)\n",
        "    formatted_texts = \"\\n\".join(data_dict[\"context\"][\"texts\"])\n",
        "    messages = []\n",
        "\n",
        "    # Adding image(s) to the messages if present\n",
        "    if data_dict[\"context\"][\"images\"]:\n",
        "        for image in data_dict[\"context\"][\"images\"]:\n",
        "            image_message = {\n",
        "                \"type\": \"image_url\",\n",
        "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "            }\n",
        "            messages.append(image_message)\n",
        "\n",
        "    # Adding the text for analysis\n",
        "    text_message = {\n",
        "        \"type\": \"text\",\n",
        "        \"text\": (\n",
        "            \"You are a helpful assistant.\\n\"\n",
        "            \"You will be given a mixed info(s) .\\n\"\n",
        "            \"Use this information to provide relevant information to the user question. \\n\"\n",
        "            f\"User-provided question: {data_dict['question']}\\n\\n\"\n",
        "            \"Text and / or tables:\\n\"\n",
        "            f\"{formatted_texts}\"\n",
        "        ),\n",
        "    }\n",
        "    messages.append(text_message)\n",
        "    return [HumanMessage(content=messages)]"
      ],
      "metadata": {
        "id": "vIg41Ew4O9gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
      ],
      "metadata": {
        "id": "1YzsW4DWO_FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_modal_rag_chain(retriever):\n",
        "    \"\"\"\n",
        "    Multi-modal RAG chain\n",
        "    \"\"\"\n",
        "\n",
        "    # Multi-modal LLM\n",
        "    model = ChatOpenAI(temperature=0, model=\"gpt-4-turbo-2024-04-09\", max_tokens=1024)\n",
        "\n",
        "\n",
        "    # RAG pipeline\n",
        "    chain = (\n",
        "        {\n",
        "            \"context\": retriever | RunnableLambda(split_image_text_types),\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "        | RunnableLambda(img_prompt_func)\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "V7hsYQgpPAQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag = multi_modal_rag_chain(retriever_multi_vector_img)"
      ],
      "metadata": {
        "id": "YgiThWmbPCWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag"
      ],
      "metadata": {
        "id": "ObTJB-EnPDnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1=\n",
        "query2="
      ],
      "metadata": {
        "id": "X7jMZX21PF1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag.invoke(query1)"
      ],
      "metadata": {
        "id": "NGR0OZmbPKA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_multimodal_rag.invoke(query2)"
      ],
      "metadata": {
        "id": "TOSlpgn3PLDE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}